{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym[atari]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Categorical\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Buffer, collect_one_episode, normalize_obs, copy_params, avg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLinear(nn.Module):\n",
    "    def __init__(self, n_in, n_out, act=nn.ReLU()):\n",
    "        super(ResLinear, self).__init__()\n",
    "        self.act = act\n",
    "        self.linear = nn.Linear(n_in, n_out)\n",
    "        self.bn = nn.BatchNorm1d(n_out)\n",
    "        \n",
    "        assert(n_in == n_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.act(self.bn(self.linear(x)))\n",
    "        return h + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player(nn.Module):\n",
    "    def __init__(self, n_in=128, n_hid=100, n_out=6):\n",
    "        super(Player, self).__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(n_in, n_hid),\n",
    "                                    nn.BatchNorm1d(n_hid),\n",
    "                                    nn.ReLU(),\n",
    "                                    ResLinear(n_hid, n_hid, nn.ReLU()),\n",
    "                                    nn.Linear(n_hid, n_out))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, obs, normalized=False):\n",
    "        if normalized:\n",
    "            return self.softmax(self.layers(obs))\n",
    "        else:\n",
    "            return self.layers(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value(nn.Module):\n",
    "    def __init__(self, n_in=128, n_hid=100):\n",
    "        super(Value, self).__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(n_in, n_hid),\n",
    "                                    nn.BatchNorm1d(n_hid),\n",
    "                                    nn.ReLU(),\n",
    "                                    ResLinear(n_hid, n_hid, nn.ReLU()),\n",
    "                                    nn.Linear(n_hid, 1))\n",
    "    \n",
    "    def forward(self, obs):\n",
    "        return self.layers(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pong-ram-v0')\n",
    "# env = gym.make('Assault-ram-v0')\n",
    "\n",
    "n_frames = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a policy\n",
    "player = Player(n_in=128 * n_frames, n_hid=32, n_out=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a value estimator\n",
    "value = Value(n_in=128 * n_frames, n_hid=32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize optimizers\n",
    "opt_player = Adam(player.parameters(), lr=0.0001)\n",
    "opt_value = Adam(value.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize replay buffer\n",
    "replay_buffer = Buffer(max_items=50000, n_frames=n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid run -20.0 -20.0\n",
      "0 0\n",
      "1 0\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n",
      "10 0\n",
      "11 0\n",
      "12 0\n",
      "13 0\n",
      "14 0\n",
      "15 0\n",
      "16 0\n",
      "17 0\n",
      "18 0\n",
      "19 0\n",
      "20 0\n",
      "21 0\n",
      "22 0\n",
      "23 0\n",
      "24 0\n",
      "25 0\n",
      "26 0\n",
      "27 0\n",
      "28 0\n",
      "29 0\n",
      "30 0\n",
      "31 0\n",
      "32 0\n",
      "33 0\n",
      "34 0\n",
      "35 0\n",
      "36 0\n",
      "37 0\n",
      "38 0\n",
      "39 0\n",
      "40 0\n",
      "41 0\n",
      "42 0\n",
      "43 0\n",
      "44 0\n",
      "45 0\n",
      "46 0\n",
      "47 0\n",
      "48 0\n",
      "49 0\n",
      "50 0\n",
      "51 0\n",
      "52 0\n",
      "53 0\n",
      "54 0\n",
      "55 0\n",
      "56 0\n",
      "57 0\n",
      "58 0\n",
      "59 0\n",
      "60 0\n",
      "61 0\n",
      "62 0\n",
      "63 0\n",
      "64 0\n",
      "65 0\n",
      "66 0\n",
      "67 0\n",
      "68 0\n",
      "69 0\n",
      "70 0\n",
      "71 0\n",
      "72 0\n",
      "73 0\n",
      "74 0\n",
      "75 0\n",
      "76 0\n",
      "77 0\n",
      "78 0\n",
      "79 0\n",
      "80 0\n",
      "81 0\n",
      "82 0\n",
      "83 0\n",
      "84 0\n",
      "85 0\n",
      "86 0\n",
      "87 0\n",
      "88 0\n",
      "89 0\n",
      "90 0\n",
      "91 0\n",
      "92 0\n",
      "93 0\n",
      "94 0\n",
      "95 0\n",
      "96 0\n",
      "97 0\n",
      "98 0\n",
      "99 0\n",
      "100 0\n",
      "101 0\n",
      "102 0\n",
      "103 0\n",
      "104 0\n",
      "105 0\n",
      "106 0\n",
      "107 0\n",
      "108 0\n",
      "109 0\n",
      "110 0\n",
      "111 0\n",
      "112 0\n",
      "113 0\n",
      "114 0\n",
      "115 0\n",
      "116 0\n",
      "117 0\n",
      "118 0\n",
      "119 0\n",
      "120 0\n",
      "121 0\n",
      "122 0\n",
      "123 0\n",
      "124 0\n",
      "125 0\n",
      "126 0\n",
      "127 0\n",
      "128 0\n",
      "129 0\n",
      "130 0\n",
      "131 0\n",
      "132 0\n",
      "133 0\n",
      "134 0\n",
      "135 0\n",
      "136 0\n",
      "137 0\n",
      "138 0\n",
      "139 0\n",
      "140 0\n",
      "141 0\n",
      "142 0\n",
      "143 0\n",
      "144 0\n",
      "145 0\n",
      "146 0\n",
      "147 0\n",
      "148 0\n",
      "149 0\n",
      "150 0\n",
      "151 0\n",
      "152 0\n",
      "153 0\n",
      "154 0\n",
      "155 0\n",
      "156 0\n",
      "157 0\n",
      "158 0\n",
      "159 0\n",
      "160 0\n",
      "161 0\n",
      "162 0\n",
      "163 0\n",
      "164 0\n",
      "165 0\n",
      "166 0\n",
      "167 0\n",
      "168 0\n",
      "169 0\n",
      "170 0\n",
      "171 0\n",
      "172 0\n",
      "173 0\n",
      "174 0\n",
      "175 0\n",
      "176 0\n",
      "177 0\n",
      "178 0\n",
      "179 0\n",
      "180 0\n",
      "181 0\n",
      "182 0\n",
      "183 0\n",
      "184 0\n",
      "185 0\n",
      "186 0\n",
      "187 0\n",
      "188 0\n",
      "189 0\n",
      "190 0\n",
      "191 0\n",
      "192 0\n",
      "193 0\n",
      "194 0\n",
      "195 0\n",
      "196 0\n",
      "197 0\n",
      "198 0\n",
      "199 0\n",
      "200 0\n",
      "201 0\n",
      "202 0\n",
      "203 0\n",
      "204 0\n",
      "205 0\n",
      "206 0\n",
      "207 0\n",
      "208 0\n",
      "209 0\n",
      "210 0\n",
      "211 0\n",
      "212 0\n",
      "213 0\n",
      "214 0\n",
      "215 0\n",
      "216 0\n",
      "217 0\n",
      "218 0\n",
      "219 0\n",
      "220 0\n",
      "221 0\n",
      "222 0\n",
      "223 0\n",
      "224 0\n",
      "225 0\n",
      "226 0\n",
      "227 0\n",
      "228 0\n",
      "229 0\n",
      "230 0\n",
      "231 0\n",
      "232 0\n",
      "233 0\n",
      "234 0\n",
      "235 0\n",
      "236 0\n",
      "237 0\n",
      "238 0\n",
      "239 0\n",
      "240 0\n",
      "241 0\n",
      "242 0\n",
      "243 0\n",
      "244 0\n",
      "245 0\n",
      "246 0\n",
      "247 0\n",
      "248 0\n",
      "249 0\n",
      "250 0\n",
      "251 0\n",
      "252 0\n",
      "253 0\n",
      "254 0\n",
      "255 0\n",
      "256 0\n",
      "257 0\n",
      "258 0\n",
      "259 0\n",
      "260 0\n",
      "261 0\n",
      "262 0\n",
      "263 0\n",
      "264 0\n",
      "265 0\n",
      "266 0\n",
      "267 0\n",
      "268 0\n",
      "269 0\n",
      "270 0\n",
      "271 0\n",
      "272 0\n",
      "273 0\n",
      "274 0\n",
      "275 0\n",
      "276 0\n",
      "277 0\n",
      "278 0\n",
      "279 0\n",
      "280 0\n",
      "281 0\n",
      "282 0\n",
      "283 0\n",
      "284 0\n",
      "285 0\n",
      "286 0\n",
      "287 0\n",
      "288 0\n",
      "289 0\n",
      "290 0\n",
      "291 0\n",
      "292 0\n",
      "293 0\n",
      "294 0\n",
      "295 0\n",
      "296 0\n",
      "297 0\n",
      "298 0\n",
      "299 0\n",
      "300 0\n",
      "301 0\n",
      "302 0\n",
      "303 0\n",
      "304 0\n",
      "305 0\n",
      "306 0\n",
      "307 0\n",
      "308 0\n",
      "309 0\n",
      "310 0\n",
      "311 0\n",
      "312 0\n",
      "313 0\n",
      "314 0\n",
      "315 0\n",
      "316 0\n",
      "317 0\n",
      "318 0\n",
      "319 0\n",
      "320 0\n",
      "321 0\n",
      "322 0\n",
      "323 0\n",
      "324 0\n",
      "325 0\n",
      "326 0\n",
      "327 0\n",
      "328 0\n",
      "329 0\n",
      "330 0\n",
      "331 0\n",
      "332 0\n",
      "333 0\n",
      "334 0\n",
      "335 0\n",
      "336 0\n",
      "337 0\n",
      "338 0\n",
      "339 0\n",
      "340 0\n",
      "341 0\n",
      "342 0\n",
      "343 0\n",
      "344 0\n",
      "345 0\n",
      "346 0\n",
      "347 0\n",
      "348 0\n",
      "349 0\n",
      "350 0\n",
      "351 0\n",
      "352 0\n",
      "353 0\n",
      "354 0\n",
      "355 0\n",
      "356 0\n",
      "357 0\n",
      "358 0\n",
      "359 0\n",
      "360 0\n",
      "361 0\n",
      "362 0\n",
      "363 0\n",
      "364 0\n",
      "365 0\n",
      "366 0\n",
      "367 0\n",
      "368 0\n",
      "369 0\n",
      "370 0\n",
      "371 0\n",
      "372 0\n",
      "373 0\n",
      "374 0\n",
      "375 0\n",
      "376 0\n",
      "377 0\n",
      "378 0\n",
      "379 0\n",
      "380 0\n",
      "381 0\n",
      "382 0\n",
      "383 0\n",
      "384 0\n",
      "385 0\n",
      "386 0\n",
      "387 0\n",
      "388 0\n",
      "389 0\n",
      "390 0\n",
      "391 0\n",
      "392 0\n",
      "393 0\n",
      "394 0\n",
      "395 0\n",
      "396 0\n",
      "397 0\n",
      "398 0\n",
      "399 0\n",
      "400 0\n",
      "401 0\n",
      "402 0\n",
      "403 0\n",
      "404 0\n",
      "405 0\n",
      "406 0\n",
      "407 0\n",
      "408 0\n",
      "409 0\n",
      "410 0\n",
      "411 0\n",
      "412 0\n",
      "413 0\n",
      "414 0\n",
      "415 0\n",
      "416 0\n",
      "417 0\n",
      "418 0\n",
      "419 0\n",
      "420 0\n",
      "421 0\n",
      "422 0\n",
      "423 0\n",
      "424 0\n",
      "425 0\n",
      "426 0\n",
      "427 0\n",
      "428 0\n",
      "429 0\n",
      "430 0\n",
      "431 0\n",
      "432 0\n",
      "433 0\n",
      "434 0\n",
      "435 0\n",
      "436 0\n",
      "437 0\n",
      "438 0\n",
      "439 0\n",
      "440 0\n",
      "441 0\n",
      "442 0\n",
      "443 0\n",
      "444 0\n",
      "445 0\n",
      "446 0\n",
      "447 0\n",
      "448 0\n",
      "449 0\n",
      "450 0\n",
      "451 0\n",
      "452 0\n",
      "453 0\n",
      "454 0\n",
      "455 0\n",
      "456 0\n",
      "457 0\n",
      "458 0\n",
      "459 0\n",
      "460 0\n",
      "461 0\n",
      "462 0\n",
      "463 0\n",
      "464 0\n",
      "465 0\n",
      "466 0\n",
      "467 0\n",
      "468 0\n",
      "469 0\n",
      "470 0\n",
      "471 0\n",
      "472 0\n",
      "473 0\n",
      "474 0\n",
      "475 0\n",
      "476 0\n",
      "477 0\n",
      "478 0\n",
      "479 0\n",
      "480 0\n",
      "481 0\n",
      "482 0\n",
      "483 0\n",
      "484 0\n",
      "485 0\n",
      "486 0\n",
      "487 0\n",
      "488 0\n",
      "489 0\n",
      "490 0\n",
      "491 0\n",
      "492 0\n",
      "493 0\n",
      "494 0\n",
      "495 0\n",
      "496 0\n",
      "497 0\n",
      "498 0\n",
      "499 0\n",
      "500 0\n",
      "501 0\n",
      "502 0\n",
      "503 0\n",
      "504 0\n",
      "505 0\n",
      "506 0\n",
      "507 0\n",
      "508 0\n",
      "509 0\n",
      "510 0\n",
      "511 0\n",
      "512 0\n",
      "513 0\n",
      "514 0\n",
      "515 0\n",
      "516 0\n",
      "517 0\n",
      "518 0\n",
      "519 0\n",
      "520 0\n",
      "521 0\n",
      "522 0\n",
      "523 0\n",
      "524 0\n",
      "525 0\n",
      "526 0\n",
      "527 0\n",
      "528 0\n",
      "529 0\n",
      "530 0\n",
      "531 0\n",
      "532 0\n",
      "533 0\n",
      "534 0\n",
      "535 0\n",
      "536 0\n",
      "537 0\n",
      "538 0\n",
      "539 0\n",
      "540 0\n",
      "541 0\n",
      "542 0\n",
      "543 0\n",
      "544 0\n",
      "545 0\n",
      "546 0\n",
      "547 0\n",
      "548 0\n",
      "549 0\n",
      "550 0\n",
      "551 0\n",
      "552 0\n",
      "553 0\n",
      "554 0\n",
      "555 0\n",
      "556 0\n",
      "557 0\n",
      "558 0\n",
      "559 0\n",
      "560 0\n",
      "561 0\n",
      "562 0\n",
      "563 0\n",
      "564 0\n",
      "565 0\n",
      "566 0\n",
      "567 0\n",
      "568 0\n",
      "569 0\n",
      "570 0\n",
      "571 0\n",
      "572 0\n",
      "573 0\n",
      "574 0\n",
      "575 0\n",
      "576 0\n",
      "577 0\n",
      "578 0\n",
      "579 0\n",
      "580 0\n",
      "581 0\n",
      "582 0\n",
      "583 0\n",
      "584 0\n",
      "585 0\n",
      "586 0\n",
      "587 0\n",
      "588 0\n",
      "589 0\n",
      "590 0\n",
      "591 0\n",
      "592 0\n",
      "593 0\n",
      "594 0\n",
      "595 0\n",
      "596 0\n",
      "597 0\n",
      "598 0\n",
      "599 0\n",
      "600 0\n",
      "601 0\n",
      "602 0\n",
      "603 0\n",
      "604 0\n",
      "605 0\n",
      "606 0\n",
      "607 0\n",
      "608 0\n",
      "609 0\n",
      "610 0\n",
      "611 0\n",
      "612 0\n",
      "613 0\n",
      "614 0\n",
      "615 0\n",
      "616 0\n",
      "617 0\n",
      "618 0\n",
      "619 0\n",
      "620 0\n",
      "621 0\n",
      "622 0\n",
      "623 0\n",
      "624 0\n",
      "625 0\n",
      "626 0\n",
      "627 0\n",
      "628 0\n",
      "629 0\n",
      "630 0\n",
      "631 0\n",
      "632 0\n",
      "633 0\n",
      "634 0\n",
      "635 0\n",
      "636 0\n",
      "637 0\n",
      "638 0\n",
      "639 0\n",
      "640 0\n",
      "641 0\n",
      "642 0\n",
      "643 0\n",
      "644 0\n",
      "645 0\n",
      "646 0\n",
      "647 0\n",
      "648 0\n",
      "649 0\n",
      "650 0\n",
      "651 0\n",
      "652 0\n",
      "653 0\n",
      "654 0\n",
      "655 0\n",
      "656 0\n",
      "657 0\n",
      "658 0\n",
      "659 0\n",
      "660 0\n",
      "661 0\n",
      "662 0\n",
      "663 0\n",
      "664 0\n",
      "665 0\n",
      "666 0\n",
      "667 0\n",
      "668 0\n",
      "669 0\n",
      "670 0\n",
      "671 0\n",
      "672 0\n",
      "673 0\n",
      "674 0\n",
      "675 0\n",
      "676 0\n",
      "677 0\n",
      "678 0\n",
      "679 0\n",
      "680 0\n",
      "681 0\n",
      "682 0\n",
      "683 0\n",
      "684 0\n",
      "685 0\n",
      "686 0\n",
      "687 0\n",
      "688 0\n",
      "689 0\n",
      "690 0\n",
      "691 0\n",
      "692 0\n",
      "693 0\n",
      "694 0\n",
      "695 0\n",
      "696 0\n",
      "697 0\n",
      "698 0\n",
      "699 0\n",
      "700 0\n",
      "701 0\n",
      "702 0\n",
      "703 0\n",
      "704 0\n",
      "705 0\n",
      "706 0\n",
      "707 0\n",
      "708 0\n",
      "709 0\n",
      "710 0\n",
      "711 0\n",
      "712 0\n",
      "713 0\n",
      "714 0\n",
      "715 0\n",
      "716 0\n",
      "717 0\n",
      "718 0\n",
      "719 0\n",
      "720 0\n",
      "721 0\n",
      "722 0\n",
      "723 0\n",
      "724 0\n",
      "725 0\n",
      "726 0\n",
      "727 0\n",
      "728 0\n",
      "729 0\n",
      "730 0\n",
      "731 0\n",
      "732 0\n",
      "733 0\n",
      "734 0\n",
      "735 0\n",
      "736 0\n",
      "737 0\n",
      "738 0\n",
      "739 0\n",
      "740 0\n",
      "741 0\n",
      "742 0\n",
      "743 0\n",
      "744 0\n",
      "745 0\n",
      "746 0\n",
      "747 0\n",
      "748 0\n",
      "749 0\n",
      "750 0\n",
      "751 0\n",
      "752 0\n",
      "753 0\n",
      "754 0\n",
      "755 0\n",
      "756 0\n",
      "757 0\n",
      "758 0\n",
      "759 0\n",
      "760 0\n",
      "761 0\n",
      "762 0\n",
      "763 0\n",
      "764 0\n",
      "765 0\n",
      "766 0\n",
      "767 0\n",
      "768 0\n",
      "769 0\n",
      "770 0\n",
      "771 0\n",
      "772 0\n",
      "773 0\n",
      "774 0\n",
      "775 0\n",
      "776 0\n",
      "777 0\n",
      "778 0\n",
      "779 0\n",
      "780 0\n",
      "781 0\n",
      "782 0\n",
      "783 0\n",
      "784 0\n",
      "785 0\n",
      "786 0\n",
      "787 0\n",
      "788 0\n",
      "789 0\n",
      "790 0\n",
      "791 0\n",
      "792 0\n",
      "793 0\n",
      "794 0\n",
      "795 0\n",
      "796 0\n",
      "797 0\n",
      "798 0\n",
      "799 0\n",
      "800 0\n",
      "801 0\n",
      "802 0\n",
      "803 0\n",
      "804 0\n",
      "805 0\n",
      "806 0\n",
      "807 0\n",
      "808 0\n",
      "809 0\n",
      "810 0\n",
      "811 0\n",
      "812 0\n",
      "813 0\n",
      "814 0\n",
      "815 0\n",
      "816 0\n",
      "817 0\n",
      "818 0\n",
      "819 0\n",
      "820 0\n",
      "821 0\n",
      "822 0\n",
      "823 0\n",
      "824 0\n",
      "825 0\n",
      "826 0\n",
      "827 0\n",
      "828 0\n",
      "829 0\n",
      "830 0\n",
      "831 0\n",
      "832 0\n",
      "833 0\n",
      "834 0\n",
      "835 0\n",
      "836 0\n",
      "837 0\n",
      "838 0\n",
      "839 0\n",
      "840 0\n",
      "841 0\n",
      "842 0\n",
      "843 0\n",
      "844 0\n",
      "845 0\n",
      "846 0\n",
      "847 0\n",
      "848 0\n",
      "849 0\n",
      "850 0\n",
      "851 0\n",
      "852 0\n",
      "853 0\n",
      "854 0\n",
      "855 0\n",
      "856 0\n",
      "857 0\n",
      "858 0\n",
      "859 0\n",
      "860 0\n",
      "861 0\n",
      "862 0\n",
      "863 0\n",
      "864 0\n",
      "865 0\n",
      "866 0\n",
      "867 0\n",
      "868 0\n",
      "869 0\n",
      "870 0\n",
      "871 0\n",
      "872 0\n",
      "873 0\n",
      "874 0\n",
      "875 0\n",
      "876 0\n",
      "877 0\n",
      "878 0\n",
      "879 0\n",
      "880 0\n",
      "881 0\n",
      "882 0\n",
      "883 0\n",
      "884 0\n",
      "885 0\n",
      "886 0\n",
      "887 0\n",
      "888 0\n",
      "889 0\n",
      "890 0\n",
      "891 0\n",
      "892 0\n",
      "893 0\n",
      "894 0\n",
      "895 0\n",
      "896 0\n",
      "897 0\n",
      "898 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1000 x 256], m2: [128 x 32] at /Users/administrator/nightlies/pytorch-1.0.0/wheel_build_dirs/conda_3.6/conda/conda-bld/pytorch_1544137972173/work/aten/src/TH/generic/THTensorMath.cpp:940",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9aeabfc68b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'current'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'current'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'crew'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a942248d7823>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [1000 x 256], m2: [128 x 32] at /Users/administrator/nightlies/pytorch-1.0.0/wheel_build_dirs/conda_3.6/conda/conda-bld/pytorch_1544137972173/work/aten/src/TH/generic/THTensorMath.cpp:940"
     ]
    }
   ],
   "source": [
    "n_iter = 1000\n",
    "init_collect = 1\n",
    "n_collect = 1\n",
    "n_value = 150\n",
    "n_policy = 150\n",
    "disp_iter = 1\n",
    "val_iter = 1\n",
    "\n",
    "max_len = 1000\n",
    "batch_size = 1000\n",
    "\n",
    "ent_coeff = 0. #0.001\n",
    "discount_factor = .95\n",
    "\n",
    "value_loss = -numpy.Inf\n",
    "ret = -numpy.Inf\n",
    "entropy = -numpy.Inf\n",
    "valid_ret = -numpy.Inf\n",
    "\n",
    "return_history = []\n",
    "\n",
    "for ni in range(n_iter):\n",
    "    player.eval()\n",
    "\n",
    "    if numpy.mod(ni, val_iter) == 0:\n",
    "        _, _, _, _, _, ret_ = collect_one_episode(env, player, max_len=max_len, deterministic=True, n_frames=n_frames)\n",
    "        return_history.append(ret_)\n",
    "        if valid_ret == -numpy.Inf:\n",
    "            valid_ret = ret_\n",
    "        else:\n",
    "            valid_ret = 0.9 * valid_ret + 0.1 * ret_\n",
    "        print('Valid run', ret_, valid_ret)\n",
    "\n",
    "    # collect some episodes using the current policy\n",
    "    # and push (obs,a,r,p(a)) tuples to the replay buffer.\n",
    "    nc = n_collect\n",
    "    if ni == 0:\n",
    "        nc = init_collect\n",
    "    for ci in range(nc):\n",
    "        o_, r_, c_, a_, ap_, ret_ = collect_one_episode(env, player, max_len=max_len, discount_factor=discount_factor, n_frames=n_frames)\n",
    "        replay_buffer.add(o_, r_, c_, a_, ap_)\n",
    "        if ret == -numpy.Inf:\n",
    "            ret = ret_\n",
    "        else:\n",
    "            ret = 0.9 * ret + 0.1 * ret_\n",
    "    \n",
    "    # fit a value function\n",
    "    value.train()\n",
    "    for vi in range(n_value):\n",
    "        opt_player.zero_grad()\n",
    "        opt_value.zero_grad()\n",
    "        \n",
    "        batch = replay_buffer.sample(batch_size)\n",
    "\n",
    "        batch_x = torch.from_numpy(numpy.stack([ex['current']['obs'] for ex in batch]).astype('float32')).to(device)\n",
    "        batch_y = torch.from_numpy(numpy.stack([ex['current']['crew'] for ex in batch]).astype('float32')).to(device)\n",
    "        pred_y = value(batch_x).squeeze()\n",
    "        loss_ = ((batch_y - pred_y) ** 2)\n",
    "        \n",
    "        batch_a = torch.from_numpy(numpy.stack([ex['current']['act'] for ex in batch]).astype('float32')[:,None]).to(device)\n",
    "        batch_pi = player(batch_x, normalized=True)\n",
    "        batch_q = torch.from_numpy(numpy.stack([ex['current']['prob'] for ex in batch]).astype('float32')).to(device)\n",
    "        logp = torch.log(batch_pi.gather(1, batch_a.long()))\n",
    "\n",
    "        # (clipped) importance weight: \n",
    "        # because the policy may have changed since the tuple was collected.\n",
    "        iw = torch.exp((logp.clone().detach() - torch.log(batch_q)).clamp(max=0.))\n",
    "    \n",
    "        loss = iw * loss_\n",
    "        \n",
    "        loss = loss.mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        opt_value.step()\n",
    "        \n",
    "    if value_loss < 0.:\n",
    "        value_loss = loss_.mean().item()\n",
    "    else:\n",
    "        value_loss = 0.9 * value_loss + 0.1 * loss_.mean().item()\n",
    "    \n",
    "    if numpy.mod(ni, disp_iter) == 0:\n",
    "        print('# plays', (ni+1) * n_collect, 'return', ret, 'value_loss', value_loss, 'entropy', -entropy)\n",
    "    \n",
    "    # fit a policy\n",
    "    value.eval()\n",
    "    player.train()\n",
    "    for pi in range(n_policy):\n",
    "        opt_player.zero_grad()\n",
    "        opt_value.zero_grad()\n",
    "        \n",
    "        batch = replay_buffer.sample(batch_size)\n",
    "        \n",
    "        batch_x = torch.from_numpy(numpy.stack([ex['current']['obs'] for ex in batch]).astype('float32')).to(device)\n",
    "        batch_r = torch.from_numpy(numpy.stack([ex['current']['crew'] for ex in batch]).astype('float32')[:,None]).to(device)\n",
    "        batch_v = value(batch_x)\n",
    "        batch_a = torch.from_numpy(numpy.stack([ex['current']['act'] for ex in batch]).astype('float32')[:,None]).to(device)\n",
    "        batch_q = torch.from_numpy(numpy.stack([ex['current']['prob'] for ex in batch]).astype('float32')).to(device)\n",
    "\n",
    "        batch_pi = player(batch_x, normalized=True)\n",
    "        \n",
    "        logp = torch.log(batch_pi.gather(1, batch_a.long()))\n",
    "        \n",
    "        # advantage\n",
    "        adv = batch_r - batch_v.clone().detach()\n",
    "        adv = adv / adv.abs().max().clamp(min=1.)\n",
    "        \n",
    "        loss = -(adv * logp)\n",
    "        \n",
    "        # (clipped) importance weight: \n",
    "        # because the policy may have changed since the tuple was collected.\n",
    "        iw = torch.exp((logp.clone().detach() - torch.log(batch_q)).clamp(max=0.))\n",
    "    \n",
    "        loss = iw * loss\n",
    "        \n",
    "        # entropy regularization: though, it doesn't look necessary in this specific case.\n",
    "        ent = (batch_pi * torch.log(batch_pi)).sum(1)\n",
    "        \n",
    "        if entropy == -numpy.Inf:\n",
    "            entropy = ent.mean().item()\n",
    "        else:\n",
    "            entropy = 0.9 * entropy + 0.1 * ent.mean().item()\n",
    "        \n",
    "        loss = (loss + ent_coeff * ent).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        opt_player.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.figure()\n",
    "\n",
    "plot.plot(return_history)\n",
    "plot.grid(True)\n",
    "plot.xlabel('# of plays x {}'.format(n_collect))\n",
    "plot.ylabel('Return over the episode of length {}'.format(max_len))\n",
    "\n",
    "plot.show()\n",
    "plot.savefig('return_log.pdf', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(player.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let the final policy play the pong longer\n",
    "player.eval()\n",
    "_, _, _, _, _, ret_ = collect_one_episode(env, player, max_len=1000000, deterministic=True, rendering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
