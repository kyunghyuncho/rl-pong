{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym[atari]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Categorical\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLinear(nn.Module):\n",
    "    def __init__(self, n_in, n_out, act=nn.ReLU()):\n",
    "        super(ResLinear, self).__init__()\n",
    "        self.act = act\n",
    "        self.linear = nn.Linear(n_in, n_out)\n",
    "        self.bn = nn.BatchNorm1d(n_out)\n",
    "        \n",
    "        assert(n_in == n_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.act(self.bn(self.linear(x)))\n",
    "        return h + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player(nn.Module):\n",
    "    def __init__(self, n_in=128, n_hid=100, n_out=6):\n",
    "        super(Player, self).__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(n_in, n_hid),\n",
    "                                    nn.BatchNorm1d(n_hid),\n",
    "                                    nn.ReLU(),\n",
    "                                    ResLinear(n_hid, n_hid, nn.ReLU()),\n",
    "                                    nn.Linear(n_hid, n_out))\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, obs, normalized=False):\n",
    "        if normalized:\n",
    "            return self.softmax(self.layers(obs))\n",
    "        else:\n",
    "            return self.layers(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value(nn.Module):\n",
    "    def __init__(self, n_in=128, n_hid=100):\n",
    "        super(Value, self).__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(n_in, n_hid),\n",
    "                                    nn.BatchNorm1d(n_hid),\n",
    "                                    nn.ReLU(),\n",
    "                                    ResLinear(n_hid, n_hid, nn.ReLU()),\n",
    "                                    nn.Linear(n_hid, 1))\n",
    "    \n",
    "    def forward(self, obs):\n",
    "        return self.layers(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_params(from_, to_):\n",
    "    for f_, t_ in zip(from_.parameters(), to_.parameters()):\n",
    "        t_.data.copy_(f_.data)\n",
    "        \n",
    "def avg_params(from_, to_, coeff=0.95):\n",
    "    for f_, t_ in zip(from_.parameters(), to_.parameters()):\n",
    "        t_.data.copy_(coeff * t_.data + (1.-coeff) * f_.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_obs(obs):\n",
    "    return obs.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pong-ram-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect data\n",
    "def collect_one_episode(env, player, max_len=50, discount_factor=0.9, deterministic=False, rendering=False, verbose=False):\n",
    "    episode = []\n",
    "\n",
    "    observations = []\n",
    "\n",
    "    rewards = []\n",
    "    crewards = []\n",
    "\n",
    "    actions = []\n",
    "    action_probs = []\n",
    "\n",
    "    obs = env.reset()\n",
    "    \n",
    "    for ml in range(max_len):\n",
    "        if rendering:\n",
    "            env.render()\n",
    "            sleep(0.05)\n",
    "            \n",
    "        obs = normalize_obs(obs)\n",
    "\n",
    "        out_probs = player(torch.from_numpy(obs[None,:]), normalized=True).squeeze()\n",
    "        \n",
    "        if deterministic:\n",
    "            action = numpy.argmax(out_probs.data.numpy())\n",
    "            if verbose:\n",
    "                print(out_probs, action)\n",
    "        else:\n",
    "            act_dist = Categorical(out_probs)\n",
    "            action = act_dist.sample().item()\n",
    "        action_prob = out_probs[action].item()\n",
    "\n",
    "        observations.append(obs)\n",
    "        actions.append(action)\n",
    "        action_probs.append(action_prob)\n",
    "\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if deterministic and verbose:\n",
    "            print(reward, done)\n",
    "        \n",
    "        rewards.append(reward)\n",
    "\n",
    "    rewards = numpy.array(rewards)\n",
    "\n",
    "    # it's probably not the best idea to compute the discounted cumulative returns here, but well..\n",
    "    for ri in range(len(rewards)):\n",
    "        factors = (discount_factor ** numpy.arange(len(rewards)-ri))\n",
    "        crewards.append(numpy.sum(rewards[ri:] * factors))\n",
    "        \n",
    "    # discard the final 10%, because it really doesn't give me a good signal due to the unbounded horizon\n",
    "    # this is only for training, not for computing the total return of the episode of the given length\n",
    "    discard = max_len // 10\n",
    "        \n",
    "    return observations[:-discard], crewards[:-discard], actions[:-discard], action_probs[:-discard], rewards.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple implementation of FIFO-based replay buffer\n",
    "class Buffer:\n",
    "    def __init__(self, max_items=10000):\n",
    "        self.max_items = max_items\n",
    "        self.buffer = []\n",
    "        \n",
    "    def add(self, observations, crewards, actions, action_probs):\n",
    "        new_n = len(observations)\n",
    "        old_n = len(self.buffer)\n",
    "        if new_n + old_n > self.max_items:\n",
    "            del self.buffer[:new_n]\n",
    "        for o, c, a, p in zip(observations, crewards, actions, action_probs):\n",
    "            self.buffer.append((o, c, a, p))\n",
    "            \n",
    "    def sample(self, n=100):\n",
    "        idxs = numpy.random.choice(len(self.buffer),n)\n",
    "        return [self.buffer[ii] for ii in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a policy\n",
    "player = Player(n_in=128, n_hid=32, n_out=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a value estimator\n",
    "value = Value(n_in=128, n_hid=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize optimizers\n",
    "opt_player = Adam(player.parameters(), lr=0.0001)\n",
    "opt_value = Adam(value.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize replay buffer\n",
    "replay_buffer = Buffer(max_items=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyunghyuncho/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid run -20.0\n",
      "# plays 1 return -16.542701650999998 value_loss 0.26948466897010803 entropy inf\n",
      "Valid run -20.0\n",
      "# plays 2 return -16.8884314859 value_loss 0.26769939363002776 entropy 1.7384350076243655\n",
      "Valid run -20.0\n",
      "# plays 3 return -16.59958833731 value_loss 0.26605464190244676 entropy 1.7384942054500834\n",
      "Valid run -20.0\n",
      "# plays 4 return -16.539629503579 value_loss 0.2576955691277981 entropy 1.738444260076567\n",
      "Valid run -20.0\n",
      "# plays 5 return -16.785666553221102 value_loss 0.2503564210504294 entropy 1.7377413517327507\n",
      "Valid run -20.0\n",
      "# plays 6 return -16.707099897898992 value_loss 0.24135280267328027 entropy 1.7375544968376355\n",
      "Valid run -20.0\n",
      "# plays 7 return -16.836389908109094 value_loss 0.23014565511879329 entropy 1.7375649876272936\n",
      "Valid run -20.0\n",
      "# plays 8 return -16.852750917298184 value_loss 0.22176235649887027 entropy 1.737181644152176\n",
      "Valid run -20.0\n",
      "# plays 9 return -16.867475825568366 value_loss 0.21341569632801385 entropy 1.7371947061278707\n",
      "Valid run -20.0\n",
      "# plays 10 return -16.38072824301153 value_loss 0.20369676420551217 entropy 1.737248392830969\n",
      "Valid run -20.0\n",
      "# plays 11 return -15.942655418710377 value_loss 0.19469143974299738 entropy 1.737749058250515\n",
      "Valid run -20.0\n",
      "# plays 12 return -16.04838987683934 value_loss 0.18514278928204336 entropy 1.738286349313358\n",
      "Valid run -20.0\n",
      "# plays 13 return -16.143550889155406 value_loss 0.17555756181267462 entropy 1.7387711017186747\n",
      "Valid run -20.0\n",
      "# plays 14 return -16.52919580023987 value_loss 0.16429491543579902 entropy 1.7390076146331142\n",
      "Valid run -20.0\n",
      "# plays 15 return -16.676276220215883 value_loss 0.15583875212498433 entropy 1.7391100623228355\n",
      "Valid run -20.0\n",
      "# plays 16 return -16.408648598194294 value_loss 0.1489533954867237 entropy 1.739626176057665\n",
      "Valid run -20.0\n",
      "# plays 17 return -16.367783738374865 value_loss 0.1411622270055276 entropy 1.7399514680458856\n",
      "Valid run -20.0\n",
      "# plays 18 return -16.431005364537377 value_loss 0.13381033203968362 entropy 1.7403390337753424\n",
      "Valid run -20.0\n",
      "# plays 19 return -16.58790482808364 value_loss 0.12592178415032287 entropy 1.7403838810916767\n",
      "Valid run -20.0\n",
      "# plays 20 return -16.329114345275276 value_loss 0.1199339903662091 entropy 1.7403315697194361\n",
      "Valid run -20.0\n",
      "# plays 21 return -16.19620291074775 value_loss 0.11299814341391494 entropy 1.7404663561052245\n",
      "Valid run -20.0\n",
      "# plays 22 return -16.076582619672976 value_loss 0.10687251627080474 entropy 1.7402515806914833\n",
      "Valid run -20.0\n",
      "# plays 23 return -15.96892435770568 value_loss 0.10128752877980025 entropy 1.7403132706076363\n",
      "Valid run -20.0\n",
      "# plays 24 return -15.97203192193511 value_loss 0.0958715158611794 entropy 1.7404761020963109\n",
      "Valid run -20.0\n",
      "# plays 25 return -16.1748287297416 value_loss 0.09117129210325417 entropy 1.7405492422115714\n",
      "Valid run -21.0\n",
      "# plays 26 return -16.05734585676744 value_loss 0.08648489427887503 entropy 1.740489708143652\n",
      "Valid run -20.0\n",
      "# plays 27 return -16.051611271090696 value_loss 0.08170228313496504 entropy 1.739950819613174\n",
      "Valid run -20.0\n",
      "# plays 28 return -16.346450143981627 value_loss 0.07810096989057178 entropy 1.7396446818224356\n",
      "Valid run -20.0\n",
      "# plays 29 return -16.211805129583468 value_loss 0.07434584282322271 entropy 1.7397902328800157\n",
      "Valid run -20.0\n",
      "# plays 30 return -15.890624616625121 value_loss 0.07124467156067678 entropy 1.7398937112958797\n",
      "Valid run -20.0\n",
      "# plays 31 return -16.00156215496261 value_loss 0.06780435334207285 entropy 1.739608328670334\n",
      "Valid run -20.0\n",
      "# plays 32 return -15.801405939466349 value_loss 0.06505963637436929 entropy 1.7394834186223016\n",
      "Valid run -20.0\n",
      "# plays 33 return -15.921265345519714 value_loss 0.0627572456062332 entropy 1.7400098632547354\n",
      "Valid run -20.0\n",
      "# plays 34 return -15.429138810967743 value_loss 0.0606154648864712 entropy 1.7405092639259123\n",
      "Valid run -20.0\n",
      "# plays 35 return -15.786224929870968 value_loss 0.05829454869667701 entropy 1.7407761123215788\n",
      "Valid run -20.0\n",
      "# plays 36 return -15.307602436883872 value_loss 0.05593913229382049 entropy 1.7405687716463234\n",
      "Valid run -20.0\n",
      "# plays 37 return -15.376842193195484 value_loss 0.05495396158465157 entropy 1.7404889019759335\n",
      "Valid run -20.0\n",
      "# plays 38 return -15.639157973875937 value_loss 0.054604029146150444 entropy 1.7406913704003464\n",
      "Valid run -20.0\n",
      "# plays 39 return -15.575242176488343 value_loss 0.05428655414639326 entropy 1.7409729097678233\n",
      "Valid run -21.0\n",
      "# plays 40 return -15.717717958839508 value_loss 0.053217881639525996 entropy 1.740787503499274\n",
      "Valid run -20.0\n",
      "# plays 41 return -15.045946162955557 value_loss 0.051538719209783417 entropy 1.7406147944390464\n",
      "Valid run -20.0\n",
      "# plays 42 return -15.541351546660001 value_loss 0.0506135878468333 entropy 1.740635487738366\n",
      "Valid run -20.0\n",
      "# plays 43 return -15.987216391994002 value_loss 0.04902786716861531 entropy 1.7406046640047488\n",
      "Valid run -20.0\n",
      "# plays 44 return -15.688494752794602 value_loss 0.04749907587507074 entropy 1.7404270995357545\n",
      "Valid run -20.0\n",
      "# plays 45 return -15.619645277515142 value_loss 0.047571460466432916 entropy 1.7403044244051458\n",
      "Valid run -20.0\n",
      "# plays 46 return -15.657680749763628 value_loss 0.04687071299032719 entropy 1.7400071325617552\n",
      "Valid run -20.0\n",
      "# plays 47 return -15.291912674787266 value_loss 0.04696184803971366 entropy 1.7396659684878673\n",
      "Valid run -20.0\n",
      "# plays 48 return -15.36272140730854 value_loss 0.04599943080480739 entropy 1.7394517690916722\n",
      "Valid run -20.0\n",
      "# plays 49 return -15.726449266577687 value_loss 0.045627264922283695 entropy 1.7393394593707752\n",
      "Valid run -20.0\n",
      "# plays 50 return -15.45380433991992 value_loss 0.04509143307395811 entropy 1.7394544563742778\n",
      "Valid run -20.0\n",
      "# plays 51 return -15.808423905927928 value_loss 0.04506757542122634 entropy 1.7394071364083987\n",
      "Valid run -20.0\n",
      "# plays 52 return -15.627581515335136 value_loss 0.04495895297493844 entropy 1.7394802767982802\n",
      "Valid run -20.0\n",
      "# plays 53 return -15.364823363801623 value_loss 0.044897384713586945 entropy 1.7395225144852908\n",
      "Valid run -20.0\n",
      "# plays 54 return -14.82834102742146 value_loss 0.04528241919323514 entropy 1.739496179106463\n",
      "Valid run -20.0\n",
      "# plays 55 return -14.945506924679314 value_loss 0.04468422740857044 entropy 1.7393187493220297\n",
      "Valid run -20.0\n",
      "# plays 56 return -15.050956232211384 value_loss 0.04358991855526185 entropy 1.739050157767789\n",
      "Valid run -20.0\n",
      "# plays 57 return -14.945860608990246 value_loss 0.043221219621397994 entropy 1.7389013800534507\n",
      "Valid run -20.0\n",
      "# plays 58 return -15.251274548091223 value_loss 0.043020007081894227 entropy 1.738914046076406\n",
      "Valid run -20.0\n",
      "# plays 59 return -15.126147093282102 value_loss 0.042950404794277086 entropy 1.739509768871602\n",
      "Valid run -20.0\n",
      "# plays 60 return -15.313532383953891 value_loss 0.04228496829682112 entropy 1.7399330369110222\n",
      "Valid run -20.0\n",
      "# plays 61 return -15.482179145558504 value_loss 0.04153085340571571 entropy 1.7405185833595271\n",
      "Valid run -20.0\n",
      "# plays 62 return -15.733961231002654 value_loss 0.040323427374769766 entropy 1.7409098101842406\n",
      "Valid run -20.0\n",
      "# plays 63 return -15.360565107902389 value_loss 0.03990779278183834 entropy 1.7413066401455561\n",
      "Valid run -20.0\n",
      "# plays 64 return -15.82450859711215 value_loss 0.03924225419019035 entropy 1.7416225135489842\n",
      "Valid run -20.0\n",
      "# plays 65 return -15.742057737400936 value_loss 0.038234887861499534 entropy 1.7413046934131713\n",
      "Valid run -20.0\n",
      "# plays 66 return -15.267851963660842 value_loss 0.037694331639965786 entropy 1.741369135518239\n",
      "Valid run -20.0\n",
      "# plays 67 return -14.741066767294758 value_loss 0.03740565513130464 entropy 1.7416323315096076\n",
      "Valid run -20.0\n",
      "# plays 68 return -15.166960090565283 value_loss 0.037382875319329836 entropy 1.7417361624915633\n",
      "Valid run -20.0\n",
      "# plays 69 return -14.750264081508755 value_loss 0.03671523300797457 entropy 1.7416084673924341\n",
      "Valid run -20.0\n",
      "# plays 70 return -15.075237673357881 value_loss 0.03643177145413203 entropy 1.741638824256869\n",
      "Valid run -20.0\n",
      "# plays 71 return -15.167713906022092 value_loss 0.03639718914352337 entropy 1.7412499747162171\n",
      "Valid run -20.0\n",
      "# plays 72 return -15.450942515419884 value_loss 0.03594623416056466 entropy 1.7411402624981838\n",
      "Valid run -19.0\n",
      "# plays 73 return -15.305848263877897 value_loss 0.03602033511749117 entropy 1.7410034637731284\n",
      "Valid run -18.0\n",
      "# plays 74 return -15.275263437490107 value_loss 0.03550279168144949 entropy 1.7405192699575587\n",
      "Valid run -20.0\n",
      "# plays 75 return -14.647737093741098 value_loss 0.03558557691743453 entropy 1.7405800949440362\n",
      "Valid run -20.0\n",
      "# plays 76 return -14.98296338436699 value_loss 0.03563017848942113 entropy 1.7404920980828864\n",
      "Valid run -20.0\n",
      "# plays 77 return -14.884667045930291 value_loss 0.03622579905819981 entropy 1.740035064106472\n",
      "Valid run -20.0\n",
      "# plays 78 return -14.596200341337262 value_loss 0.03546974659054358 entropy 1.73966232957366\n",
      "Valid run -20.0\n",
      "# plays 79 return -14.136580307203536 value_loss 0.03602137506087613 entropy 1.7393436367156117\n",
      "Valid run -20.0\n",
      "# plays 80 return -14.522922276483182 value_loss 0.035965704233169485 entropy 1.7388530402389202\n",
      "Valid run -20.0\n",
      "# plays 81 return -14.370630048834865 value_loss 0.036283290738511026 entropy 1.7386516427507093\n",
      "Valid run -20.0\n",
      "# plays 82 return -14.83356704395138 value_loss 0.03619751306293721 entropy 1.7386794843091429\n",
      "Valid run -20.0\n",
      "# plays 83 return -15.250210339556242 value_loss 0.03660277252124234 entropy 1.738579815130019\n",
      "Valid run -20.0\n",
      "# plays 84 return -14.725189305600617 value_loss 0.03633856042975024 entropy 1.738084322307213\n",
      "Valid run -20.0\n",
      "# plays 85 return -15.052670375040556 value_loss 0.036117832122032366 entropy 1.7378943998992695\n",
      "Valid run -20.0\n",
      "# plays 86 return -15.2474033375365 value_loss 0.03622131333451079 entropy 1.7375772422115454\n",
      "Valid run -20.0\n",
      "# plays 87 return -15.422663003782851 value_loss 0.03604638049632854 entropy 1.7376376597572751\n",
      "Valid run -20.0\n",
      "# plays 88 return -14.780396703404566 value_loss 0.03634323115316522 entropy 1.7378101278990556\n",
      "Valid run -20.0\n",
      "# plays 89 return -15.20235703306411 value_loss 0.035953450740881195 entropy 1.7374069248911852\n",
      "Valid run -20.0\n",
      "# plays 90 return -15.1821213297577 value_loss 0.03567971643046209 entropy 1.7371164916552706\n",
      "Valid run -20.0\n",
      "# plays 91 return -15.063909196781932 value_loss 0.03562221957357826 entropy 1.736999369295065\n",
      "Valid run -20.0\n",
      "# plays 92 return -15.257518277103738 value_loss 0.03469868164311739 entropy 1.7369313722187791\n",
      "Valid run -20.0\n",
      "# plays 93 return -15.531766449393366 value_loss 0.034302809784271346 entropy 1.7369904613156757\n",
      "Valid run -20.0\n",
      "# plays 94 return -15.37858980445403 value_loss 0.03389461784761372 entropy 1.7368144888723087\n",
      "Valid run -20.0\n",
      "# plays 95 return -15.340730824008627 value_loss 0.03364582351626059 entropy 1.7365912721221939\n",
      "Valid run -21.0\n",
      "# plays 96 return -15.306657741607765 value_loss 0.033304072470496 entropy 1.7363907997166352\n",
      "Valid run -20.0\n",
      "# plays 97 return -15.17599196744699 value_loss 0.033180582866993456 entropy 1.736359582979181\n",
      "Valid run -20.0\n",
      "# plays 98 return -15.15839277070229 value_loss 0.03279799317204378 entropy 1.736155869938772\n",
      "Valid run -20.0\n",
      "# plays 99 return -15.042553493632061 value_loss 0.03233190189197739 entropy 1.7366654882420907\n",
      "Valid run -20.0\n",
      "# plays 100 return -15.038298144268856 value_loss 0.03184467365945948 entropy 1.736717996576193\n",
      "Valid run -20.0\n",
      "# plays 101 return -14.534468329841971 value_loss 0.03219997527246689 entropy 1.7366641490907826\n",
      "Valid run -20.0\n",
      "# plays 102 return -14.781021496857775 value_loss 0.031964345615014565 entropy 1.7368117457640408\n",
      "Valid run -20.0\n",
      "# plays 103 return -15.002919347172 value_loss 0.031822053238068644 entropy 1.7369739754344644\n",
      "Valid run -20.0\n",
      "# plays 104 return -15.202627412454799 value_loss 0.031435054855926 entropy 1.7370143767662627\n",
      "Valid run -20.0\n",
      "# plays 105 return -15.48236467120932 value_loss 0.031333650299057214 entropy 1.7369365577719633\n",
      "Valid run -20.0\n",
      "# plays 106 return -15.134128204088388 value_loss 0.03187598450316029 entropy 1.737089910405639\n",
      "Valid run -20.0\n",
      "# plays 107 return -15.02071538367955 value_loss 0.031872916191813684 entropy 1.7370636241222408\n",
      "Valid run -20.0\n",
      "# plays 108 return -15.018643845311594 value_loss 0.03177605238854647 entropy 1.737046851866346\n",
      "Valid run -20.0\n",
      "# plays 109 return -15.216779460780437 value_loss 0.03196768798500085 entropy 1.736360153826482\n",
      "Valid run -20.0\n",
      "# plays 110 return -15.295101514702393 value_loss 0.03175875753673718 entropy 1.736277599209064\n",
      "Valid run -20.0\n",
      "# plays 111 return -14.965591363232154 value_loss 0.0322212465302301 entropy 1.7361270489947804\n",
      "Valid run -20.0\n",
      "# plays 112 return -15.269032226908939 value_loss 0.032425069826497364 entropy 1.735917192331198\n",
      "Valid run -21.0\n",
      "# plays 113 return -15.142129004218045 value_loss 0.03266570293991601 entropy 1.7353477850481378\n",
      "Valid run -20.0\n",
      "# plays 114 return -15.327916103796241 value_loss 0.03199491790612491 entropy 1.73551008225811\n",
      "Valid run -20.0\n",
      "# plays 115 return -15.495124493416618 value_loss 0.031208778694390822 entropy 1.7350952537506485\n",
      "Valid run -20.0\n",
      "# plays 116 return -15.145612044074959 value_loss 0.0308789194227334 entropy 1.7350264180765271\n",
      "Valid run -17.0\n",
      "# plays 117 return -14.331050839667462 value_loss 0.030817960889733688 entropy 1.7344608774088106\n",
      "Valid run -20.0\n",
      "# plays 118 return -14.297945755700717 value_loss 0.03142096640908437 entropy 1.7336853235174041\n",
      "Valid run -20.0\n",
      "# plays 119 return -14.068151180130645 value_loss 0.03143415377059922 entropy 1.7335301821155862\n",
      "Valid run -19.0\n",
      "# plays 120 return -13.86133606211758 value_loss 0.03112656515555989 entropy 1.7327630526691655\n",
      "Valid run -20.0\n",
      "# plays 121 return -13.975202455905823 value_loss 0.031430635005689364 entropy 1.7320268387251567\n",
      "Valid run -20.0\n",
      "# plays 122 return -13.87768221031524 value_loss 0.0315545832965881 entropy 1.7317804284875784\n",
      "Valid run -20.0\n",
      "# plays 123 return -13.789913989283718 value_loss 0.0323719421792725 entropy 1.7312532376774459\n",
      "Valid run -20.0\n",
      "# plays 124 return -13.510922590355346 value_loss 0.032768654653611715 entropy 1.7308209462416255\n",
      "Valid run -20.0\n",
      "# plays 125 return -13.159830331319812 value_loss 0.033514439608916285 entropy 1.7304028229129949\n",
      "Valid run -17.0\n",
      "# plays 126 return -13.44384729818783 value_loss 0.033898469772575476 entropy 1.7296746538404646\n",
      "Valid run -19.0\n",
      "# plays 127 return -13.699462568369047 value_loss 0.034386853396867076 entropy 1.7292975083221693\n",
      "Valid run -20.0\n",
      "# plays 128 return -13.729516311532143 value_loss 0.03519711943266483 entropy 1.7288895737860444\n",
      "Valid run -20.0\n",
      "# plays 129 return -13.456564680378929 value_loss 0.035789085270145765 entropy 1.7287273414585829\n",
      "Valid run -18.0\n",
      "# plays 130 return -13.610908212341036 value_loss 0.03610358864770463 entropy 1.728320397653387\n",
      "Valid run -19.0\n",
      "# plays 131 return -13.349817391106932 value_loss 0.036583177200312594 entropy 1.7284071428598675\n",
      "Valid run -20.0\n",
      "# plays 132 return -13.214835651996239 value_loss 0.0370800751012759 entropy 1.728433217076673\n",
      "Valid run -16.0\n",
      "# plays 133 return -13.593352086796617 value_loss 0.03671567209621041 entropy 1.7280326034917148\n",
      "Valid run -19.0\n",
      "# plays 134 return -13.434016878116957 value_loss 0.03624205426627191 entropy 1.7274900451375412\n",
      "Valid run -19.0\n",
      "# plays 135 return -13.29061519030526 value_loss 0.03699566806483679 entropy 1.7268963424206514\n",
      "Valid run -20.0\n",
      "# plays 136 return -13.161553671274735 value_loss 0.03746906900520694 entropy 1.7266316055351874\n",
      "Valid run -17.0\n",
      "# plays 137 return -13.345398304147261 value_loss 0.03936696261866902 entropy 1.7261780570833114\n",
      "Valid run -20.0\n",
      "# plays 138 return -13.910858473732535 value_loss 0.03974929752085222 entropy 1.7262211714437863\n",
      "Valid run -20.0\n",
      "# plays 139 return -13.919772626359283 value_loss 0.03926305668473494 entropy 1.726106588917713\n",
      "Valid run -20.0\n",
      "# plays 140 return -13.527795363723355 value_loss 0.039845933290603035 entropy 1.7261660259696086\n",
      "Valid run -20.0\n",
      "# plays 141 return -13.57501582735102 value_loss 0.03962623829151595 entropy 1.7259529285792923\n",
      "Valid run -20.0\n",
      "# plays 142 return -13.41751424461592 value_loss 0.039142433966744584 entropy 1.7258175089430772\n",
      "Valid run -20.0\n",
      "# plays 143 return -13.975762820154328 value_loss 0.039343767612172946 entropy 1.725742387532362\n",
      "Valid run -20.0\n",
      "# plays 144 return -14.078186538138896 value_loss 0.03872646383851211 entropy 1.725821288104063\n",
      "Valid run -20.0\n",
      "# plays 145 return -13.970367884325007 value_loss 0.03812851414748526 entropy 1.7262927105498849\n",
      "Valid run -20.0\n",
      "# plays 146 return -13.773331095892509 value_loss 0.037033778889493614 entropy 1.7263500475546147\n",
      "Valid run -20.0\n",
      "# plays 147 return -13.79599798630326 value_loss 0.03672342893199605 entropy 1.726285744039782\n",
      "Valid run -20.0\n",
      "# plays 148 return -13.816398187672934 value_loss 0.03604410626783802 entropy 1.7258959549652368\n",
      "Valid run -20.0\n",
      "# plays 149 return -13.53475836890564 value_loss 0.036172665625466414 entropy 1.7257983530549856\n",
      "Valid run -20.0\n",
      "# plays 150 return -13.381282532015078 value_loss 0.03665005077688709 entropy 1.7248127896735306\n",
      "Valid run -20.0\n",
      "# plays 151 return -13.24315427881357 value_loss 0.03592536312880053 entropy 1.7245730803678285\n",
      "Valid run -20.0\n",
      "# plays 152 return -13.518838850932212 value_loss 0.03609687354453147 entropy 1.7244360563979357\n",
      "Valid run -20.0\n",
      "# plays 153 return -13.066954965838992 value_loss 0.03630293137986428 entropy 1.7243008279635499\n",
      "Valid run -20.0\n",
      "# plays 154 return -12.660259469255093 value_loss 0.03775965364717514 entropy 1.7238865032732686\n",
      "Valid run -20.0\n",
      "# plays 155 return -12.994233522329584 value_loss 0.037978166940299304 entropy 1.7238058294498362\n",
      "Valid run -20.0\n",
      "# plays 156 return -12.694810170096625 value_loss 0.03831148782594887 entropy 1.7233090765829961\n",
      "Valid run -20.0\n",
      "# plays 157 return -12.425329153086963 value_loss 0.038566662870859095 entropy 1.7227193007248607\n",
      "Valid run -20.0\n",
      "# plays 158 return -12.582796237778268 value_loss 0.03882343866200595 entropy 1.722900427508967\n",
      "Valid run -20.0\n",
      "# plays 159 return -12.324516614000443 value_loss 0.03848402058575764 entropy 1.7226858210785116\n",
      "Valid run -20.0\n",
      "# plays 160 return -12.5920649526004 value_loss 0.038804656092770826 entropy 1.7223013874626967\n",
      "Valid run -20.0\n",
      "# plays 161 return -12.53285845734036 value_loss 0.03853825292686933 entropy 1.721905559776232\n",
      "Valid run -20.0\n",
      "# plays 162 return -12.979572611606326 value_loss 0.03880343343347591 entropy 1.7217044594926754\n",
      "Valid run -20.0\n",
      "# plays 163 return -12.681615350445693 value_loss 0.039114917864176174 entropy 1.721354282078063\n",
      "Valid run -20.0\n",
      "# plays 164 return -12.813453815401123 value_loss 0.03908022877553631 entropy 1.7203908120788345\n",
      "Valid run -20.0\n",
      "# plays 165 return -12.932108433861012 value_loss 0.03933425966184911 entropy 1.71944232692142\n",
      "Valid run -20.0\n",
      "# plays 166 return -12.838897590474911 value_loss 0.03886421671463469 entropy 1.718298874185083\n",
      "Valid run -20.0\n",
      "# plays 167 return -12.955007831427421 value_loss 0.03879000679510909 entropy 1.7179019339729629\n",
      "Valid run -20.0\n",
      "# plays 168 return -12.85950704828468 value_loss 0.03850090632609795 entropy 1.7179048787754616\n",
      "Valid run -20.0\n",
      "# plays 169 return -12.873556343456213 value_loss 0.03806108575855736 entropy 1.7175855917339324\n",
      "Valid run -20.0\n",
      "# plays 170 return -12.886200709110593 value_loss 0.037940969021276034 entropy 1.7170808924265688\n",
      "Valid run -20.0\n",
      "# plays 171 return -13.297580638199534 value_loss 0.037424736426313575 entropy 1.7168912016952942\n",
      "Valid run -18.0\n",
      "# plays 172 return -12.86782257437958 value_loss 0.036885212248003355 entropy 1.71631668476922\n",
      "Valid run -20.0\n",
      "# plays 173 return -13.481040316941623 value_loss 0.03618691225537885 entropy 1.716093307318647\n",
      "Valid run -20.0\n",
      "# plays 174 return -13.432936285247463 value_loss 0.0359801466139188 entropy 1.7157157532258456\n",
      "Valid run -20.0\n",
      "# plays 175 return -13.789642656722716 value_loss 0.03578098921823775 entropy 1.7150820325933522\n",
      "Valid run -20.0\n",
      "# plays 176 return -13.610678391050445 value_loss 0.03530508760823258 entropy 1.715099468398847\n",
      "Valid run -19.0\n",
      "# plays 177 return -13.849610551945402 value_loss 0.034882768288673 entropy 1.714436987027892\n",
      "Valid run -20.0\n",
      "# plays 178 return -13.964649496750862 value_loss 0.034424265589196416 entropy 1.7141970409004172\n",
      "Valid run -20.0\n",
      "# plays 179 return -13.868184547075778 value_loss 0.033682979597937104 entropy 1.7143176799191098\n",
      "Valid run -20.0\n",
      "# plays 180 return -13.6813660923682 value_loss 0.033375348854921195 entropy 1.7145539801041598\n",
      "Valid run -20.0\n",
      "# plays 181 return -13.613229483131382 value_loss 0.032959775589879094 entropy 1.7146465426112332\n",
      "Valid run -20.0\n",
      "# plays 182 return -13.851906534818244 value_loss 0.03219859116194463 entropy 1.7150221477227596\n",
      "Valid run -20.0\n",
      "# plays 183 return -13.76671588133642 value_loss 0.03160306662694647 entropy 1.7155270369226367\n",
      "Valid run -20.0\n",
      "# plays 184 return -13.490044293202779 value_loss 0.030844106677556347 entropy 1.716002913016258\n",
      "Valid run -20.0\n",
      "# plays 185 return -13.441039863882501 value_loss 0.030218911941395084 entropy 1.7159510754925391\n",
      "Valid run -20.0\n",
      "# plays 186 return -13.496935877494252 value_loss 0.03015243491579224 entropy 1.7157700145732329\n",
      "Valid run -20.0\n",
      "# plays 187 return -13.647242289744828 value_loss 0.030062361637197103 entropy 1.7159685636989548\n",
      "Valid run -20.0\n",
      "# plays 188 return -13.682518060770345 value_loss 0.029673163328566104 entropy 1.7161270520712797\n",
      "Valid run -20.0\n",
      "# plays 189 return -13.814266254693312 value_loss 0.029706464768050268 entropy 1.7162593072609194\n",
      "Valid run -20.0\n",
      "# plays 190 return -14.232839629223982 value_loss 0.030017609426913998 entropy 1.7151199265314745\n",
      "Valid run -20.0\n",
      "# plays 191 return -13.709555666301585 value_loss 0.030442591037933536 entropy 1.7153001823181884\n",
      "Valid run -20.0\n",
      "# plays 192 return -13.638600099671427 value_loss 0.030316964076385955 entropy 1.7147255961508832\n",
      "Valid run -20.0\n",
      "# plays 193 return -13.474740089704284 value_loss 0.030267743836128173 entropy 1.7141211087217063\n",
      "Valid run -20.0\n",
      "# plays 194 return -13.127266080733856 value_loss 0.030867332059398404 entropy 1.7139000510041336\n",
      "Valid run -20.0\n",
      "# plays 195 return -13.01453947266047 value_loss 0.03157738827608983 entropy 1.7135744373691406\n",
      "Valid run -20.0\n",
      "# plays 196 return -13.213085525394423 value_loss 0.0319114351982739 entropy 1.7129523837779752\n",
      "Valid run -20.0\n",
      "# plays 197 return -13.39177697285498 value_loss 0.031575699125069356 entropy 1.7126011712207394\n",
      "Valid run -20.0\n",
      "# plays 198 return -13.652599275569482 value_loss 0.0331396500536841 entropy 1.7118946830381332\n",
      "Valid run -20.0\n",
      "# plays 199 return -13.787339348012534 value_loss 0.03347801814398543 entropy 1.7109921797970118\n",
      "Valid run -20.0\n",
      "# plays 200 return -13.10860541321128 value_loss 0.03351737320352831 entropy 1.7105801788526185\n",
      "Valid run -20.0\n",
      "# plays 201 return -13.197744871890151 value_loss 0.034605773627125365 entropy 1.7103061915905209\n",
      "Valid run -20.0\n",
      "# plays 202 return -13.477970384701136 value_loss 0.03462320589068217 entropy 1.7094895229820188\n",
      "Valid run -20.0\n",
      "# plays 203 return -13.130173346231022 value_loss 0.03413867803403154 entropy 1.70926539274736\n",
      "Valid run -20.0\n",
      "# plays 204 return -13.01715601160792 value_loss 0.033892921525136364 entropy 1.708540040068408\n",
      "Valid run -20.0\n",
      "# plays 205 return -12.815440410447128 value_loss 0.03429683394839978 entropy 1.7084309679819512\n",
      "Valid run -20.0\n",
      "# plays 206 return -12.933896369402415 value_loss 0.034073508285975 entropy 1.708704006455255\n",
      "Valid run -20.0\n",
      "# plays 207 return -12.640506732462175 value_loss 0.03480350248828132 entropy 1.7083524903850336\n",
      "Valid run -20.0\n",
      "# plays 208 return -12.676456059215958 value_loss 0.0353568447930926 entropy 1.708211985495824\n",
      "Valid run -20.0\n",
      "# plays 209 return -12.608810453294364 value_loss 0.03576365813344543 entropy 1.7079772502877264\n",
      "Valid run -20.0\n",
      "# plays 210 return -12.647929407964929 value_loss 0.03703168925401412 entropy 1.7078224300828264\n",
      "Valid run -20.0\n",
      "# plays 211 return -12.583136467168437 value_loss 0.03719672282120743 entropy 1.7075049577263763\n",
      "Valid run -20.0\n",
      "# plays 212 return -12.324822820451594 value_loss 0.0375096247605785 entropy 1.7069785773452057\n",
      "Valid run -21.0\n",
      "# plays 213 return -12.192340538406434 value_loss 0.03748012633731702 entropy 1.7070477025841297\n",
      "Valid run -20.0\n",
      "# plays 214 return -12.073106484565791 value_loss 0.0379544981713063 entropy 1.7065705531539446\n",
      "Valid run -20.0\n",
      "# plays 215 return -11.565795836109212 value_loss 0.037786958819177735 entropy 1.706317220129929\n",
      "Valid run -20.0\n",
      "# plays 216 return -11.209216252498292 value_loss 0.037680301328492455 entropy 1.7062917978962435\n",
      "Valid run -20.0\n",
      "# plays 217 return -11.388294627248463 value_loss 0.037587010049813054 entropy 1.7060126959008253\n",
      "Valid run -20.0\n",
      "# plays 218 return -11.649465164523617 value_loss 0.036894565314644336 entropy 1.7058445797194248\n",
      "Valid run -20.0\n",
      "# plays 219 return -11.484518648071255 value_loss 0.037404318592483186 entropy 1.7052695354903358\n",
      "Valid run -20.0\n",
      "# plays 220 return -11.63606678326413 value_loss 0.0378707933648238 entropy 1.7049380227246969\n",
      "Valid run -20.0\n",
      "# plays 221 return -11.872460104937717 value_loss 0.03870531289790357 entropy 1.7046475241936152\n",
      "Valid run -20.0\n",
      "# plays 222 return -11.585214094443947 value_loss 0.03885955060137169 entropy 1.7040174406671464\n",
      "Valid run -19.0\n",
      "# plays 223 return -11.726692684999552 value_loss 0.03895589249980023 entropy 1.7031587531325694\n",
      "Valid run -20.0\n",
      "# plays 224 return -11.654023416499596 value_loss 0.03996485505388591 entropy 1.7026960786513758\n",
      "Valid run -20.0\n",
      "# plays 225 return -11.188621074849635 value_loss 0.040841359948096394 entropy 1.701863939638945\n",
      "Valid run -20.0\n",
      "# plays 226 return -11.469758967364672 value_loss 0.041654347528497324 entropy 1.701245093021535\n",
      "Valid run -20.0\n",
      "# plays 227 return -11.922783070628205 value_loss 0.04165560191823239 entropy 1.7019838780761103\n",
      "Valid run -20.0\n",
      "# plays 228 return -12.030504763565386 value_loss 0.04227131324368592 entropy 1.7010378681031078\n",
      "Valid run -20.0\n",
      "# plays 229 return -12.627454287208849 value_loss 0.04154298686109075 entropy 1.7008900247482628\n",
      "Valid run -20.0\n",
      "# plays 230 return -11.964708858487963 value_loss 0.04051384538223227 entropy 1.7014106025077576\n",
      "Valid run -20.0\n",
      "# plays 231 return -11.368237972639166 value_loss 0.040834373621432905 entropy 1.701113774228773\n",
      "Valid run -20.0\n",
      "# plays 232 return -11.53141417537525 value_loss 0.04108054352249705 entropy 1.7012424348771664\n",
      "Valid run -15.0\n",
      "# plays 233 return -11.678272757837727 value_loss 0.040291419960075646 entropy 1.7011785574820184\n",
      "Valid run -15.0\n",
      "# plays 234 return -12.010445482053955 value_loss 0.040027082044196756 entropy 1.7011647617691568\n",
      "Valid run -19.0\n",
      "# plays 235 return -11.70940093384856 value_loss 0.0398484126433545 entropy 1.7011671950631828\n",
      "Valid run -15.0\n",
      "# plays 236 return -11.738460840463706 value_loss 0.03977277478916767 entropy 1.7008721855717543\n",
      "Valid run -17.0\n",
      "# plays 237 return -11.364614756417335 value_loss 0.03973496907660356 entropy 1.7017624159274165\n",
      "Valid run -20.0\n",
      "# plays 238 return -11.828153280775602 value_loss 0.03931335728206328 entropy 1.7011999115482286\n",
      "Valid run -14.0\n",
      "# plays 239 return -11.945337952698043 value_loss 0.03872742723677836 entropy 1.7011483514009091\n",
      "Valid run -18.0\n",
      "# plays 240 return -11.95080415742824 value_loss 0.0390727290176238 entropy 1.7005556845353533\n",
      "Valid run -10.0\n",
      "# plays 241 return -12.255723741685417 value_loss 0.039076281889935026 entropy 1.6996424657090445\n",
      "Valid run -18.0\n",
      "# plays 242 return -11.930151367516876 value_loss 0.03917707090496393 entropy 1.6986560297710356\n",
      "Valid run -15.0\n",
      "# plays 243 return -11.537136230765189 value_loss 0.039524032934779275 entropy 1.6986862891734036\n",
      "Valid run -20.0\n",
      "# plays 244 return -11.88342260768867 value_loss 0.0392437999078104 entropy 1.6982966318833546\n",
      "Valid run -19.0\n",
      "# plays 245 return -11.995080346919805 value_loss 0.039348621633213975 entropy 1.6976536059413017\n",
      "Valid run -12.0\n",
      "# plays 246 return -11.895572312227824 value_loss 0.03972004008283814 entropy 1.6978103961017634\n",
      "Valid run -11.0\n",
      "# plays 247 return -11.906015081005041 value_loss 0.0389510458885783 entropy 1.6982736665298839\n",
      "Valid run -13.0\n",
      "# plays 248 return -12.115413572904538 value_loss 0.03817794951908177 entropy 1.6981991375630245\n",
      "Valid run -10.0\n",
      "# plays 249 return -12.203872215614085 value_loss 0.037508816866091366 entropy 1.6980215271243706\n",
      "Valid run -13.0\n",
      "# plays 250 return -12.483484994052677 value_loss 0.03708443091631962 entropy 1.6979050689377293\n",
      "Valid run -8.0\n",
      "# plays 251 return -12.63513649464741 value_loss 0.03672969755221337 entropy 1.6966746319781099\n",
      "Valid run -10.0\n",
      "# plays 252 return -12.77162284518267 value_loss 0.03634850345571873 entropy 1.6967522658506031\n",
      "Valid run -13.0\n",
      "# plays 253 return -12.394460560664402 value_loss 0.0364471029119495 entropy 1.6959273628681535\n",
      "Valid run -5.0\n",
      "# plays 254 return -12.055014504597963 value_loss 0.036783379022193266 entropy 1.6946073926570073\n",
      "Valid run -11.0\n",
      "# plays 255 return -11.849513054138168 value_loss 0.0369622715150526 entropy 1.6946537007476987\n",
      "Valid run -7.0\n",
      "# plays 256 return -11.76456174872435 value_loss 0.03669192525761225 entropy 1.6944134188463578\n",
      "Valid run -10.0\n",
      "# plays 257 return -11.588105573851916 value_loss 0.0374780566217026 entropy 1.694041774772373\n",
      "Valid run -13.0\n",
      "# plays 258 return -11.429295016466725 value_loss 0.037486383308904254 entropy 1.6933426066388138\n",
      "Valid run -10.0\n",
      "# plays 259 return -11.786365514820053 value_loss 0.03720397896164973 entropy 1.6938834192176517\n",
      "Valid run -11.0\n",
      "# plays 260 return -11.907728963338048 value_loss 0.03726157230074096 entropy 1.6938901546089145\n",
      "Valid run -13.0\n",
      "# plays 261 return -12.016956067004244 value_loss 0.037189502778067186 entropy 1.6934246661179013\n",
      "Valid run -9.0\n",
      "# plays 262 return -11.51526046030382 value_loss 0.03671416350818931 entropy 1.6942263242219195\n",
      "Valid run -8.0\n",
      "# plays 263 return -10.963734414273437 value_loss 0.038357880714093975 entropy 1.694832655071297\n",
      "Valid run -11.0\n",
      "# plays 264 return -11.467360972846093 value_loss 0.03901927165915549 entropy 1.6957185171050209\n",
      "Valid run -9.0\n",
      "# plays 265 return -11.820624875561483 value_loss 0.039819291169017376 entropy 1.6972181967805628\n",
      "Valid run -9.0\n",
      "# plays 266 return -11.938562388005336 value_loss 0.03977333130052968 entropy 1.6973689488135255\n",
      "Valid run -10.0\n",
      "# plays 267 return -12.444706149204801 value_loss 0.039205515354376594 entropy 1.6994703473448427\n",
      "Valid run -10.0\n",
      "# plays 268 return -12.600235534284321 value_loss 0.038731895210893354 entropy 1.7000328616077667\n",
      "Valid run -14.0\n",
      "# plays 269 return -12.840211980855889 value_loss 0.03853842711974805 entropy 1.700700641938304\n",
      "Valid run -11.0\n",
      "# plays 270 return -12.956190782770301 value_loss 0.03805876460548901 entropy 1.701320509425628\n",
      "Valid run -8.0\n",
      "# plays 271 return -12.460571704493272 value_loss 0.03822688999959824 entropy 1.7025822854177004\n",
      "Valid run -13.0\n",
      "# plays 272 return -13.014514534043947 value_loss 0.037827888442775584 entropy 1.7025611532765812\n",
      "Valid run -9.0\n",
      "# plays 273 return -12.613063080639552 value_loss 0.03829571953150717 entropy 1.7033647959524707\n",
      "Valid run -11.0\n",
      "# plays 274 return -12.351756772575598 value_loss 0.03829977974951048 entropy 1.703867518568769\n",
      "Valid run -13.0\n",
      "# plays 275 return -12.716581095318038 value_loss 0.037706058686910085 entropy 1.7046929365020498\n",
      "Valid run -12.0\n",
      "# plays 276 return -12.344922985786235 value_loss 0.03720774856144608 entropy 1.7057985455088478\n",
      "Valid run -10.0\n",
      "# plays 277 return -11.910430687207613 value_loss 0.037073080825219346 entropy 1.7042642403153012\n",
      "Valid run -10.0\n",
      "# plays 278 return -12.419387618486851 value_loss 0.0372284342385022 entropy 1.7043537884180737\n",
      "Valid run -7.0\n",
      "# plays 279 return -12.177448856638167 value_loss 0.03657424505382968 entropy 1.704334670957231\n",
      "Valid run -10.0\n",
      "# plays 280 return -12.55970397097435 value_loss 0.03749504809823805 entropy 1.7040099252572345\n",
      "Valid run -10.0\n",
      "# plays 281 return -12.703733573876915 value_loss 0.03783847205561853 entropy 1.7037587742142701\n",
      "Valid run -10.0\n",
      "# plays 282 return -12.233360216489224 value_loss 0.03866481054773143 entropy 1.703448424626215\n",
      "Valid run -9.0\n",
      "# plays 283 return -11.710024194840301 value_loss 0.03903797248557399 entropy 1.7023768046546737\n",
      "Valid run -12.0\n",
      "# plays 284 return -11.839021775356272 value_loss 0.03996036295195094 entropy 1.7024676940869545\n",
      "Valid run -8.0\n",
      "# plays 285 return -11.655119597820645 value_loss 0.040670148379501746 entropy 1.7022522939545999\n",
      "Valid run -5.0\n",
      "# plays 286 return -11.989607638038581 value_loss 0.040848858815637566 entropy 1.7015062047901408\n",
      "Valid run -10.0\n",
      "# plays 287 return -12.590646874234725 value_loss 0.040911078225559595 entropy 1.7005116674990204\n",
      "Valid run -9.0\n",
      "# plays 288 return -12.731582186811254 value_loss 0.04028939323513502 entropy 1.7005950508698104\n",
      "Valid run -16.0\n",
      "# plays 289 return -12.958423968130129 value_loss 0.03993653275271172 entropy 1.7000282706171281\n",
      "Valid run -17.0\n",
      "# plays 290 return -12.662581571317116 value_loss 0.04024273918002768 entropy 1.7003482683873161\n",
      "Valid run -10.0\n",
      "# plays 291 return -12.796323414185405 value_loss 0.03977152235147289 entropy 1.7002077894908911\n",
      "Valid run -16.0\n",
      "# plays 292 return -12.416691072766865 value_loss 0.03961586678180335 entropy 1.6998508738233324\n",
      "Valid run -10.0\n",
      "# plays 293 return -12.175021965490178 value_loss 0.03897356442350064 entropy 1.7001626179348015\n",
      "Valid run -16.0\n",
      "# plays 294 return -11.65751976894116 value_loss 0.038593199790161084 entropy 1.7005994428884046\n",
      "Valid run -14.0\n",
      "# plays 295 return -11.991767792047044 value_loss 0.03772114893702379 entropy 1.7005982846757468\n",
      "Valid run -7.0\n",
      "# plays 296 return -11.79259101284234 value_loss 0.037289833032259745 entropy 1.700770945524688\n",
      "Valid run -13.0\n",
      "# plays 297 return -11.713331911558106 value_loss 0.03623546921000129 entropy 1.7000839887171346\n",
      "Valid run -13.0\n",
      "# plays 298 return -11.441998720402296 value_loss 0.036947741473781284 entropy 1.7004842105733942\n",
      "Valid run -8.0\n",
      "# plays 299 return -11.297798848362067 value_loss 0.03706867898857643 entropy 1.7002250629953353\n",
      "Valid run -12.0\n",
      "# plays 300 return -11.06801896352586 value_loss 0.036421603235805476 entropy 1.700165297160726\n",
      "Valid run -7.0\n",
      "# plays 301 return -11.261217067173275 value_loss 0.03620420957196156 entropy 1.700002377026188\n",
      "Valid run -12.0\n",
      "# plays 302 return -11.335095360455949 value_loss 0.03663521019746423 entropy 1.6995793020236476\n",
      "Valid run -6.0\n",
      "# plays 303 return -11.701585824410355 value_loss 0.036734814269508954 entropy 1.6988778303151564\n",
      "Valid run -9.0\n",
      "# plays 304 return -11.731427241969321 value_loss 0.03636258601233307 entropy 1.699061619645176\n",
      "Valid run -10.0\n",
      "# plays 305 return -11.658284517772389 value_loss 0.03643081084565768 entropy 1.697914030892171\n",
      "Valid run -10.0\n",
      "# plays 306 return -11.89245606599515 value_loss 0.036794171443669046 entropy 1.697490303122662\n",
      "Valid run -14.0\n",
      "# plays 307 return -12.303210459395634 value_loss 0.03657409500576977 entropy 1.6970210526571656\n",
      "Valid run -17.0\n",
      "# plays 308 return -12.372889413456072 value_loss 0.03685232543794445 entropy 1.697239577449039\n",
      "Valid run -15.0\n",
      "# plays 309 return -12.535600472110465 value_loss 0.036379386131597746 entropy 1.6965418736910327\n",
      "Valid run -9.0\n",
      "# plays 310 return -12.782040424899419 value_loss 0.03625700285550939 entropy 1.6972279306268874\n",
      "Valid run -17.0\n",
      "# plays 311 return -12.803836382409479 value_loss 0.03587819704875636 entropy 1.6962119002731848\n",
      "Valid run -13.0\n",
      "# plays 312 return -12.323452744168533 value_loss 0.03662838699935634 entropy 1.6950523479071962\n",
      "Valid run -15.0\n",
      "# plays 313 return -12.09110746975168 value_loss 0.036344192885030144 entropy 1.695101370143806\n",
      "Valid run -17.0\n",
      "# plays 314 return -11.981996722776513 value_loss 0.03684193898379996 entropy 1.6965876320391693\n",
      "Valid run -17.0\n",
      "# plays 315 return -12.083797050498863 value_loss 0.03694784500426228 entropy 1.6960222807709915\n",
      "Valid run -11.0\n",
      "# plays 316 return -12.175417345448977 value_loss 0.03734424918794192 entropy 1.6960228767502505\n",
      "Valid run -13.0\n",
      "# plays 317 return -12.157875610904082 value_loss 0.037409822284313055 entropy 1.6964489729576546\n",
      "Valid run -15.0\n",
      "# plays 318 return -11.942088049813673 value_loss 0.03774222855788351 entropy 1.6964004428818773\n",
      "Valid run -15.0\n",
      "# plays 319 return -11.647879244832307 value_loss 0.038146144151883256 entropy 1.6960259783723846\n",
      "Valid run -15.0\n",
      "# plays 320 return -11.583091320349077 value_loss 0.03908201470988715 entropy 1.6965942744599674\n",
      "Valid run -13.0\n",
      "# plays 321 return -11.92478218831417 value_loss 0.04016104897872559 entropy 1.697663533196579\n",
      "Valid run -13.0\n",
      "# plays 322 return -11.932303969482753 value_loss 0.04109131711139636 entropy 1.6981581780702055\n",
      "Valid run -13.0\n",
      "# plays 323 return -11.639073572534478 value_loss 0.04108409360719642 entropy 1.6976602190671486\n",
      "Valid run -10.0\n",
      "# plays 324 return -11.17516621528103 value_loss 0.041624530634339935 entropy 1.6973446279491395\n",
      "Valid run -7.0\n",
      "# plays 325 return -11.457649593752928 value_loss 0.041232425255527755 entropy 1.6972532413156485\n",
      "Valid run -9.0\n",
      "# plays 326 return -11.511884634377637 value_loss 0.040581973224536175 entropy 1.6969637797802173\n",
      "Valid run -13.0\n",
      "# plays 327 return -11.960696170939872 value_loss 0.03998482353656494 entropy 1.6979231085230868\n",
      "Valid run -15.0\n",
      "# plays 328 return -12.064626553845887 value_loss 0.04066990094335977 entropy 1.6980971425987659\n",
      "Valid run -13.0\n",
      "# plays 329 return -12.058163898461299 value_loss 0.03958633957313392 entropy 1.698287518862591\n",
      "Valid run -7.0\n",
      "# plays 330 return -12.15234750861517 value_loss 0.039948380750479344 entropy 1.698348140775574\n",
      "Valid run -13.0\n",
      "# plays 331 return -12.237112757753653 value_loss 0.039768880690987746 entropy 1.6975511409349144\n",
      "Valid run -7.0\n",
      "# plays 332 return -12.113401481978288 value_loss 0.03893870212363229 entropy 1.6977441953539083\n",
      "Valid run -8.0\n",
      "# plays 333 return -12.30206133378046 value_loss 0.03870383364910209 entropy 1.6977430641033284\n",
      "Valid run -6.0\n",
      "# plays 334 return -12.271855200402413 value_loss 0.038476795744487556 entropy 1.6973459832283584\n",
      "Valid run -5.0\n",
      "# plays 335 return -12.444669680362173 value_loss 0.03814922194920979 entropy 1.6954579860416545\n",
      "Valid run -10.0\n",
      "# plays 336 return -12.400202712325957 value_loss 0.037203427072551865 entropy 1.6940414592865396\n",
      "Valid run -6.0\n",
      "# plays 337 return -12.560182441093362 value_loss 0.036743021085429504 entropy 1.6939542306387396\n",
      "Valid run -5.0\n",
      "# plays 338 return -12.804164196984026 value_loss 0.03654251716247348 entropy 1.6936345400401542\n",
      "Valid run -10.0\n",
      "# plays 339 return -12.723747777285624 value_loss 0.035913675398032203 entropy 1.6933657558972022\n",
      "Valid run -14.0\n",
      "# plays 340 return -12.651372999557061 value_loss 0.03600109945571452 entropy 1.6919922874241486\n",
      "Valid run -9.0\n",
      "# plays 341 return -12.586235699601357 value_loss 0.03527829868348864 entropy 1.6911403370246743\n",
      "Valid run -13.0\n",
      "# plays 342 return -12.52761212964122 value_loss 0.03531771628039265 entropy 1.6906386909599165\n",
      "Valid run -9.0\n",
      "# plays 343 return -11.874850916677097 value_loss 0.03515872525850402 entropy 1.6885518902030205\n",
      "Valid run -10.0\n",
      "# plays 344 return -11.787365825009388 value_loss 0.03472680021982908 entropy 1.6877320282740524\n",
      "Valid run -7.0\n",
      "# plays 345 return -11.60862924250845 value_loss 0.03427504173363614 entropy 1.6856320437081445\n",
      "Valid run -6.0\n",
      "# plays 346 return -11.647766318257606 value_loss 0.03446279880206616 entropy 1.6851899884008024\n",
      "Valid run -14.0\n",
      "# plays 347 return -11.782989686431847 value_loss 0.034669609369046964 entropy 1.6850255897049304\n",
      "Valid run -13.0\n",
      "# plays 348 return -11.704690717788662 value_loss 0.03508824057985021 entropy 1.6852976515655318\n",
      "Valid run -5.0\n",
      "# plays 349 return -11.234221646009795 value_loss 0.036569125854450525 entropy 1.6859769867468455\n",
      "Valid run -11.0\n",
      "# plays 350 return -11.710799481408815 value_loss 0.03681067331446236 entropy 1.684955464606711\n",
      "Valid run -12.0\n",
      "# plays 351 return -11.539719533267933 value_loss 0.037395190407154194 entropy 1.6851536290190667\n",
      "Valid run -6.0\n",
      "# plays 352 return -11.985747579941139 value_loss 0.03743435774086466 entropy 1.6836411904384798\n",
      "Valid run -11.0\n",
      "# plays 353 return -11.687172821947025 value_loss 0.03785109036122457 entropy 1.6828579548309892\n",
      "Valid run -7.0\n",
      "# plays 354 return -11.618455539752322 value_loss 0.037968481075358655 entropy 1.683047003180785\n",
      "Valid run -10.0\n",
      "# plays 355 return -11.35660998577709 value_loss 0.037929313547842736 entropy 1.681384638380665\n",
      "Valid run -7.0\n",
      "# plays 356 return -11.320948987199381 value_loss 0.037545603961437676 entropy 1.681336210654315\n",
      "Valid run -8.0\n",
      "# plays 357 return -11.088854088479444 value_loss 0.038210383758565544 entropy 1.6816093283407976\n",
      "Valid run -10.0\n",
      "# plays 358 return -10.7799686796315 value_loss 0.03934361081327864 entropy 1.6809360609359103\n",
      "Valid run -3.0\n",
      "# plays 359 return -10.601971811668351 value_loss 0.03959121256475927 entropy 1.6799000262340344\n",
      "Valid run -11.0\n",
      "# plays 360 return -11.141774630501516 value_loss 0.03920915342335655 entropy 1.6795851871242493\n",
      "Valid run -4.0\n",
      "# plays 361 return -10.527597167451365 value_loss 0.03936620235709625 entropy 1.679872508078729\n",
      "Valid run -10.0\n",
      "# plays 362 return -10.574837450706228 value_loss 0.03900986325980673 entropy 1.67968843982682\n",
      "Valid run -10.0\n",
      "# plays 363 return -10.717353705635606 value_loss 0.03888543803013667 entropy 1.679064431600669\n",
      "Valid run -8.0\n",
      "# plays 364 return -11.045618335072046 value_loss 0.03913326025173639 entropy 1.6800004566424969\n",
      "Valid run -9.0\n",
      "# plays 365 return -10.94105650156484 value_loss 0.03928365038483359 entropy 1.68045882909266\n",
      "Valid run -14.0\n",
      "# plays 366 return -10.546950851408356 value_loss 0.04002511517687754 entropy 1.6796539168380702\n",
      "Valid run -13.0\n",
      "# plays 367 return -10.59225576626752 value_loss 0.03978535920218333 entropy 1.6793588465528697\n",
      "Valid run -14.0\n",
      "# plays 368 return -11.133030189640769 value_loss 0.040086677803120356 entropy 1.6793665189087328\n",
      "Valid run -9.0\n",
      "# plays 369 return -11.219727170676691 value_loss 0.04010144238190771 entropy 1.6798308670355575\n",
      "Valid run -13.0\n",
      "# plays 370 return -11.497754453609023 value_loss 0.039535659457894445 entropy 1.6789511157185606\n",
      "Valid run -18.0\n",
      "# plays 371 return -11.147979008248122 value_loss 0.040287583311485305 entropy 1.6784058496656338\n",
      "Valid run -19.0\n",
      "# plays 372 return -11.33318110742331 value_loss 0.040279989755231484 entropy 1.676996362801615\n",
      "Valid run -17.0\n",
      "# plays 373 return -11.39986299668098 value_loss 0.040168847426246115 entropy 1.6758629584114884\n",
      "Valid run -14.0\n",
      "# plays 374 return -11.959876697012884 value_loss 0.04044856610995874 entropy 1.6758059404589782\n",
      "Valid run -17.0\n",
      "# plays 375 return -11.763889027311595 value_loss 0.04075185045393418 entropy 1.6755598475740838\n",
      "Valid run -12.0\n",
      "# plays 376 return -12.087500124580437 value_loss 0.04072194361500839 entropy 1.675768347448445\n",
      "Valid run -11.0\n",
      "# plays 377 return -12.278750112122394 value_loss 0.03985788804721444 entropy 1.6759409707297799\n",
      "Valid run -11.0\n",
      "# plays 378 return -12.250875100910154 value_loss 0.0395256151178325 entropy 1.678312602851462\n",
      "Valid run -12.0\n",
      "# plays 379 return -11.925787590819139 value_loss 0.039755948879019454 entropy 1.6779798336809408\n",
      "Valid run -15.0\n",
      "# plays 380 return -11.933208831737225 value_loss 0.03942761771174911 entropy 1.6778768313337442\n",
      "Valid run -11.0\n",
      "# plays 381 return -12.239887948563503 value_loss 0.03971570166015008 entropy 1.676978188685133\n",
      "Valid run -8.0\n",
      "# plays 382 return -12.215899153707152 value_loss 0.03927252529916208 entropy 1.676708518923806\n",
      "Valid run -13.0\n",
      "# plays 383 return -12.394309238336438 value_loss 0.03784420867732502 entropy 1.675619674995167\n",
      "Valid run -11.0\n",
      "# plays 384 return -12.454878314502796 value_loss 0.037733119994145664 entropy 1.6765589853823242\n",
      "Valid run -9.0\n",
      "# plays 385 return -11.809390483052516 value_loss 0.03721215071059051 entropy 1.6764433271483101\n",
      "Valid run -7.0\n",
      "# plays 386 return -12.228451434747264 value_loss 0.036873556972534506 entropy 1.6762021032793826\n",
      "Valid run -6.0\n",
      "# plays 387 return -12.105606291272537 value_loss 0.03669763942151461 entropy 1.6748201980610773\n",
      "Valid run -11.0\n",
      "# plays 388 return -11.795045662145284 value_loss 0.035617420319520185 entropy 1.6741417356385484\n",
      "Valid run -8.0\n",
      "# plays 389 return -12.215541095930757 value_loss 0.035377950662794186 entropy 1.6756332641460792\n",
      "Valid run -13.0\n",
      "# plays 390 return -12.093986986337681 value_loss 0.03535120109715087 entropy 1.6741943469645113\n",
      "Valid run -15.0\n",
      "# plays 391 return -12.084588287703912 value_loss 0.03587637211380621 entropy 1.6732834823034348\n",
      "Valid run -11.0\n",
      "# plays 392 return -11.876129458933521 value_loss 0.03596757157592374 entropy 1.6728183242649246\n",
      "Valid run -8.0\n",
      "# plays 393 return -11.788516513040168 value_loss 0.0362846673633015 entropy 1.6726398685189068\n",
      "Valid run -6.0\n",
      "# plays 394 return -11.509664861736152 value_loss 0.036103270227195845 entropy 1.672915998111033\n",
      "Valid run -9.0\n",
      "# plays 395 return -11.558698375562535 value_loss 0.036951065159871004 entropy 1.67314155402604\n",
      "Valid run -8.0\n",
      "# plays 396 return -11.302828538006283 value_loss 0.036813005519241535 entropy 1.6724967898628609\n",
      "Valid run -11.0\n",
      "# plays 397 return -11.172545684205655 value_loss 0.03689153727501373 entropy 1.6724936891342153\n",
      "Valid run -10.0\n",
      "# plays 398 return -11.355291115785091 value_loss 0.03655758860656387 entropy 1.6727317941046869\n",
      "Valid run -6.0\n",
      "# plays 399 return -11.119762004206583 value_loss 0.035904865045387445 entropy 1.6715201332591116\n",
      "Valid run -10.0\n",
      "# plays 400 return -11.407785803785925 value_loss 0.03590456075582406 entropy 1.6710075138828002\n",
      "Valid run -12.0\n",
      "# plays 401 return -11.167007223407333 value_loss 0.03607392171424777 entropy 1.6701498311950582\n",
      "Valid run -8.0\n",
      "# plays 402 return -11.5503065010666 value_loss 0.03659582086863056 entropy 1.6691396642523424\n",
      "Valid run -6.0\n",
      "# plays 403 return -11.49527585095994 value_loss 0.036170778707819595 entropy 1.668551888237629\n",
      "Valid run -9.0\n",
      "# plays 404 return -11.445748265863946 value_loss 0.03580217670156725 entropy 1.6678723193946137\n",
      "Valid run -11.0\n",
      "# plays 405 return -11.301173439277552 value_loss 0.035923747218437496 entropy 1.6686970315578675\n",
      "Valid run -11.0\n",
      "# plays 406 return -11.171056095349797 value_loss 0.03581388339113072 entropy 1.6684313675468379\n",
      "Valid run -7.0\n",
      "# plays 407 return -11.75395048581482 value_loss 0.03564813959340044 entropy 1.6679839182325473\n",
      "Valid run -10.0\n",
      "# plays 408 return -11.478555437233338 value_loss 0.03606886694794704 entropy 1.667230248403988\n",
      "Valid run -8.0\n",
      "# plays 409 return -11.030699893510004 value_loss 0.03599362064867445 entropy 1.6668411447605833\n",
      "Valid run -4.0\n",
      "# plays 410 return -10.827629904159004 value_loss 0.03691897606375123 entropy 1.666848966383575\n",
      "Valid run -7.0\n",
      "# plays 411 return -11.144866913743105 value_loss 0.03722899950017606 entropy 1.666950054337577\n",
      "Valid run -10.0\n",
      "# plays 412 return -10.830380222368795 value_loss 0.03668750640574164 entropy 1.6656096976453492\n",
      "Valid run -7.0\n",
      "# plays 413 return -10.447342200131915 value_loss 0.038299033270684485 entropy 1.6646484806401824\n",
      "Valid run -9.0\n",
      "# plays 414 return -10.502607980118723 value_loss 0.03912095805383409 entropy 1.662547034530242\n",
      "Valid run -7.0\n",
      "# plays 415 return -10.352347182106852 value_loss 0.03988171589711324 entropy 1.66186071167221\n",
      "Valid run -6.0\n",
      "# plays 416 return -10.217112463896168 value_loss 0.039763788259080196 entropy 1.6587853492509437\n",
      "Valid run -13.0\n",
      "# plays 417 return -10.295401217506551 value_loss 0.040012930595324465 entropy 1.6591522164065748\n",
      "Valid run -19.0\n",
      "# plays 418 return -9.965861095755896 value_loss 0.040534935680132535 entropy 1.6573184509950933\n",
      "Valid run -11.0\n",
      "# plays 419 return -9.969274986180306 value_loss 0.04121732655504474 entropy 1.6560166252861834\n",
      "Valid run -15.0\n",
      "# plays 420 return -10.672347487562277 value_loss 0.0411196159720939 entropy 1.6556908366012628\n",
      "Valid run -13.0\n",
      "# plays 421 return -10.60511273880605 value_loss 0.04047770715360536 entropy 1.6545268183726294\n",
      "Valid run -17.0\n",
      "# plays 422 return -10.544601464925444 value_loss 0.0409277852619114 entropy 1.653201601228837\n",
      "Valid run -8.0\n",
      "# plays 423 return -10.590141318432899 value_loss 0.04065294016102753 entropy 1.6513874581149013\n",
      "Valid run -17.0\n",
      "# plays 424 return -10.43112718658961 value_loss 0.04057935244172634 entropy 1.6511614951942357\n",
      "Valid run -12.0\n",
      "# plays 425 return -10.488014467930649 value_loss 0.04045408583876331 entropy 1.6514457257626862\n",
      "Valid run -12.0\n",
      "# plays 426 return -10.439213021137585 value_loss 0.04001168750700509 entropy 1.6525647983467429\n",
      "Valid run -12.0\n",
      "# plays 427 return -9.895291719023826 value_loss 0.04007008158842166 entropy 1.6531035600955597\n",
      "Valid run -13.0\n",
      "# plays 428 return -9.405762547121443 value_loss 0.03986134067487215 entropy 1.653270682494004\n",
      "Valid run -15.0\n",
      "# plays 429 return -9.765186292409298 value_loss 0.040493059697551986 entropy 1.6537926323548215\n",
      "Valid run -14.0\n",
      "# plays 430 return -9.888667663168368 value_loss 0.040903901123526806 entropy 1.655500625866806\n",
      "Valid run -13.0\n",
      "# plays 431 return -9.799800896851531 value_loss 0.04077363802211563 entropy 1.6563832297307481\n",
      "Valid run -13.0\n",
      "# plays 432 return -9.319820807166378 value_loss 0.0411392670263387 entropy 1.65870718019623\n",
      "Valid run -11.0\n",
      "# plays 433 return -9.48783872644974 value_loss 0.04177567405011093 entropy 1.657014700270439\n",
      "Valid run -9.0\n",
      "# plays 434 return -9.939054853804766 value_loss 0.04198513180767746 entropy 1.658744510746136\n",
      "Valid run -9.0\n",
      "# plays 435 return -9.945149368424289 value_loss 0.042801693088608254 entropy 1.6589460732640713\n",
      "Valid run -8.0\n",
      "# plays 436 return -9.850634431581861 value_loss 0.043574914342281765 entropy 1.6588759241630968\n",
      "Valid run -5.0\n",
      "# plays 437 return -9.765570988423676 value_loss 0.04379638508509179 entropy 1.6589356183084603\n",
      "Valid run -10.0\n",
      "# plays 438 return -9.68901388958131 value_loss 0.04466407873228711 entropy 1.6583154711380947\n",
      "Valid run -6.0\n",
      "# plays 439 return -10.220112500623179 value_loss 0.04455368782277872 entropy 1.65817373562759\n",
      "Valid run -9.0\n",
      "# plays 440 return -9.59810125056086 value_loss 0.044210683019721246 entropy 1.657575248136301\n",
      "Valid run -11.0\n",
      "# plays 441 return -9.538291125504776 value_loss 0.04400410492279864 entropy 1.6546191937856207\n",
      "Valid run -6.0\n",
      "# plays 442 return -10.084462012954297 value_loss 0.04406319772355619 entropy 1.6550630993550448\n",
      "Valid run -9.0\n",
      "# plays 443 return -9.776015811658867 value_loss 0.044460281418140506 entropy 1.6543309397828467\n",
      "Valid run -8.0\n",
      "# plays 444 return -9.69841423049298 value_loss 0.0436000143167756 entropy 1.6518113775160115\n",
      "Valid run -10.0\n",
      "# plays 445 return -9.128572807443684 value_loss 0.04436284062362152 entropy 1.6518143896951158\n",
      "Valid run -5.0\n",
      "# plays 446 return -8.815715526699314 value_loss 0.04482444531109725 entropy 1.650584290868151\n",
      "Valid run -7.0\n",
      "# plays 447 return -9.134143974029383 value_loss 0.04495917288708801 entropy 1.6499244290833937\n",
      "Valid run -7.0\n",
      "# plays 448 return -9.220729576626445 value_loss 0.044371447219682766 entropy 1.6476850873538493\n",
      "Valid run -9.0\n",
      "# plays 449 return -9.098656618963801 value_loss 0.04436929598829124 entropy 1.647324121035436\n",
      "Valid run -8.0\n",
      "# plays 450 return -9.088790957067422 value_loss 0.04365412436766303 entropy 1.646292417504713\n",
      "Valid run -9.0\n",
      "# plays 451 return -9.379911861360679 value_loss 0.04314525314727017 entropy 1.6453149108760141\n",
      "Valid run -5.0\n",
      "# plays 452 return -9.441920675224612 value_loss 0.04420131419800451 entropy 1.6444904300979828\n",
      "Valid run -10.0\n",
      "# plays 453 return -9.49772860770215 value_loss 0.0443739564690238 entropy 1.644482342392361\n",
      "Valid run -5.0\n",
      "# plays 454 return -9.847955746931936 value_loss 0.04437520025431327 entropy 1.644880958804719\n",
      "Valid run -10.0\n",
      "# plays 455 return -9.663160172238744 value_loss 0.04422913157873641 entropy 1.6453428385682902\n",
      "Valid run -7.0\n",
      "# plays 456 return -9.49684415501487 value_loss 0.043569257085919 entropy 1.6449953330362312\n",
      "Valid run -4.0\n",
      "# plays 457 return -9.747159739513382 value_loss 0.043292361699401996 entropy 1.6444785927717986\n",
      "Valid run -11.0\n",
      "# plays 458 return -10.072443765562046 value_loss 0.04302952836709588 entropy 1.6437596327222745\n",
      "Valid run -8.0\n",
      "# plays 459 return -9.865199389005841 value_loss 0.042952518767929396 entropy 1.6438319596450035\n",
      "Valid run -7.0\n",
      "# plays 460 return -10.178679450105259 value_loss 0.04200044969333678 entropy 1.6427583331663542\n",
      "Valid run -12.0\n",
      "# plays 461 return -10.560811505094733 value_loss 0.041229559030653264 entropy 1.6424754603179421\n",
      "Valid run -8.0\n",
      "# plays 462 return -10.60473035458526 value_loss 0.04140916590081563 entropy 1.6427700698904522\n",
      "Valid run -7.0\n",
      "# plays 463 return -10.144257319126735 value_loss 0.0413058213816903 entropy 1.6437120325259478\n",
      "Valid run -7.0\n",
      "# plays 464 return -10.229831587214061 value_loss 0.04146982281745869 entropy 1.64332982561634\n",
      "Valid run -8.0\n",
      "# plays 465 return -10.006848428492656 value_loss 0.04167178205556927 entropy 1.6433659207784395\n",
      "Valid run -8.0\n",
      "# plays 466 return -9.306163585643391 value_loss 0.04188013090408377 entropy 1.6412537689606812\n",
      "Valid run -10.0\n",
      "# plays 467 return -9.575547227079053 value_loss 0.04135961544856309 entropy 1.642114463385997\n",
      "Valid run -11.0\n",
      "# plays 468 return -10.117992504371148 value_loss 0.04133211117099118 entropy 1.6407682775730543\n",
      "Valid run -8.0\n",
      "# plays 469 return -9.706193253934034 value_loss 0.041356401513013764 entropy 1.6405260136835018\n",
      "Valid run -10.0\n",
      "# plays 470 return -9.33557392854063 value_loss 0.04139391500055211 entropy 1.6406800830011214\n",
      "Valid run -12.0\n",
      "# plays 471 return -8.902016535686567 value_loss 0.04116780759363845 entropy 1.6389979417824843\n",
      "Valid run -10.0\n",
      "# plays 472 return -9.21181488211791 value_loss 0.04096517035188802 entropy 1.6378383979546736\n",
      "Valid run -9.0\n",
      "# plays 473 return -9.39063339390612 value_loss 0.04170762250264759 entropy 1.6382580827673685\n",
      "Valid run -11.0\n",
      "# plays 474 return -9.251570054515508 value_loss 0.04114753752446421 entropy 1.6364724837813651\n",
      "Valid run -9.0\n",
      "# plays 475 return -9.026413049063956 value_loss 0.04119018949117882 entropy 1.6371637441580384\n",
      "Valid run -9.0\n",
      "# plays 476 return -8.82377174415756 value_loss 0.04107528801602086 entropy 1.6394946070508074\n",
      "Valid run -7.0\n",
      "# plays 477 return -8.641394569741804 value_loss 0.04044854641713465 entropy 1.6396579888060336\n",
      "Valid run -7.0\n",
      "# plays 478 return -8.777255112767623 value_loss 0.04062429480932145 entropy 1.6406845543338577\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2700c961d937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mni\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_one_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Valid run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mreturn_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-317964f23989>\u001b[0m in \u001b[0;36mcollect_one_episode\u001b[0;34m(env, player, max_len, discount_factor, deterministic, rendering, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-22a27ebb2aab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, normalized)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iter = 10000\n",
    "init_collect = 10\n",
    "n_collect = 1\n",
    "n_value = 10\n",
    "n_policy = 10\n",
    "disp_iter = 1\n",
    "val_iter = 1\n",
    "\n",
    "max_len = 1000\n",
    "batch_size = 500\n",
    "\n",
    "ent_coeff = 0. #0.001\n",
    "discount_factor = .95\n",
    "\n",
    "value_loss = -numpy.Inf\n",
    "ret = -numpy.Inf\n",
    "entropy = -numpy.Inf\n",
    "\n",
    "return_history = []\n",
    "\n",
    "for ni in range(n_iter):\n",
    "    player.eval()\n",
    "\n",
    "    if numpy.mod(ni, val_iter) == 0:\n",
    "        _, _, _, _, ret_ = collect_one_episode(env, player, max_len=max_len, deterministic=True)\n",
    "        print('Valid run', ret_)\n",
    "        return_history.append(ret_)\n",
    "\n",
    "    # collect some episodes using the current policy\n",
    "    # and push (obs,a,r,p(a)) tuples to the replay buffer.\n",
    "    nc = n_collect\n",
    "    if ni == 0:\n",
    "        nc = init_collect\n",
    "    for ci in range(nc):\n",
    "        o_, c_, a_, ap_, ret_ = collect_one_episode(env, player, max_len=max_len, discount_factor=discount_factor)\n",
    "        replay_buffer.add(o_, c_, a_, ap_)\n",
    "        if ret == -numpy.Inf:\n",
    "            ret = ret_\n",
    "        else:\n",
    "            ret = 0.9 * ret + 0.1 * ret_\n",
    "    \n",
    "    player.train()\n",
    "        \n",
    "    # fit a value function\n",
    "    for vi in range(n_value):\n",
    "        opt_player.zero_grad()\n",
    "        opt_value.zero_grad()\n",
    "        \n",
    "        batch = replay_buffer.sample(batch_size)\n",
    "        batch_x = torch.from_numpy(numpy.stack([ex[0] for ex in batch]).astype('float32'))\n",
    "        batch_y = torch.from_numpy(numpy.stack([ex[1] for ex in batch]).astype('float32'))\n",
    "        pred_y = value(batch_x).squeeze()\n",
    "        loss_ = ((batch_y - pred_y) ** 2)\n",
    "        \n",
    "        batch_a = torch.from_numpy(numpy.stack([ex[2] for ex in batch]).astype('float32')[:,None])\n",
    "        batch_pi = player(batch_x, normalized=True)\n",
    "        batch_q = torch.from_numpy(numpy.stack([ex[3] for ex in batch]).astype('float32'))\n",
    "        logp = torch.log(batch_pi.gather(1, batch_a.long()))\n",
    "\n",
    "        # (clipped) importance weight: \n",
    "        # because the policy may have changed since the tuple was collected.\n",
    "        iw = torch.exp((logp.clone().detach() - torch.log(batch_q)).clamp(max=0.))\n",
    "    \n",
    "        loss = iw * loss_\n",
    "        \n",
    "        loss = loss.mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        opt_value.step()\n",
    "        \n",
    "    if value_loss < 0.:\n",
    "        value_loss = loss_.mean().item()\n",
    "    else:\n",
    "        value_loss = 0.9 * value_loss + 0.1 * loss_.mean().item()\n",
    "    \n",
    "    if numpy.mod(ni, disp_iter) == 0:\n",
    "        print('# plays', (ni+1) * n_collect, 'return', ret, 'value_loss', value_loss, 'entropy', -entropy)\n",
    "    \n",
    "    # fit a policy\n",
    "    for pi in range(n_policy):\n",
    "        opt_player.zero_grad()\n",
    "        opt_value.zero_grad()\n",
    "        \n",
    "        batch = replay_buffer.sample(batch_size)\n",
    "        \n",
    "        batch_x = torch.from_numpy(numpy.stack([ex[0] for ex in batch]).astype('float32'))\n",
    "        batch_r = torch.from_numpy(numpy.stack([ex[1] for ex in batch]).astype('float32')[:,None])\n",
    "        batch_v = value(batch_x)\n",
    "        batch_a = torch.from_numpy(numpy.stack([ex[2] for ex in batch]).astype('float32')[:,None])\n",
    "        batch_q = torch.from_numpy(numpy.stack([ex[3] for ex in batch]).astype('float32'))\n",
    "\n",
    "        batch_pi = player(batch_x, normalized=True)\n",
    "        \n",
    "        logp = torch.log(batch_pi.gather(1, batch_a.long()))\n",
    "        \n",
    "        # advantage\n",
    "        adv = batch_r - batch_v.clone().detach()\n",
    "        \n",
    "        loss = -(adv * logp)\n",
    "        \n",
    "        # (clipped) importance weight: \n",
    "        # because the policy may have changed since the tuple was collected.\n",
    "        iw = torch.exp((logp.clone().detach() - torch.log(batch_q)).clamp(max=0.))\n",
    "    \n",
    "        loss = iw * loss\n",
    "        \n",
    "        # entropy regularization: though, it doesn't look necessary in this specific case.\n",
    "        ent = (batch_pi * torch.log(batch_pi)).sum(1)\n",
    "        \n",
    "        if entropy == -numpy.Inf:\n",
    "            entropy = ent.mean().item()\n",
    "        else:\n",
    "            entropy = 0.9 * entropy + 0.1 * ent.mean().item()\n",
    "        \n",
    "        loss = (loss + ent_coeff * ent).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        opt_player.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f4a23273854682aa6d34a618b4ef13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot.figure()\n",
    "\n",
    "plot.plot(return_history)\n",
    "plot.grid(True)\n",
    "plot.xlabel('# of plays x {}'.format(n_collect))\n",
    "plot.ylabel('Return over the episode of length {}'.format(max_len))\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyunghyuncho/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8b543fa33c12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# let the final policy play the pong longer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_one_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-317964f23989>\u001b[0m in \u001b[0;36mcollect_one_episode\u001b[0;34m(env, player, max_len, discount_factor, deterministic, rendering, verbose)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# let the final policy play the pong longer\n",
    "player.eval()\n",
    "_, _, _, _, ret_ = collect_one_episode(env, player, max_len=1000000, deterministic=True, rendering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
